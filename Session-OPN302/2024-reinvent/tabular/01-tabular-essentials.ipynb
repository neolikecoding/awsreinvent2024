{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e7d4675",
   "metadata": {},
   "source": [
    "# AutoGluon Tabular - Essential Functionality\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/master/docs/tutorials/tabular/tabular-essentials.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/master/docs/tutorials/tabular/tabular-essentials.ipynb)\n",
    "\n",
    "\n",
    "Via a simple `fit()` call, AutoGluon can produce highly-accurate models to predict the values in one column of a data table based on the rest of the columns' values. Use AutoGluon with tabular data for both classification and regression problems. This tutorial demonstrates how to use AutoGluon to produce a classification model that predicts whether or not a customer of a bank exited the bank (\"Exited\" = 1). \n",
    "\n",
    "First, we need to install AutoGluon using the below code. This should take 1-2 minutes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa00faab-252f-44c9-b8f7-57131aa8251c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.10.15 environment at: /home/ec2-user/anaconda3/envs/python3\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m12 packages\u001b[0m \u001b[2min 132ms\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m3 packages\u001b[0m \u001b[2min 2.21s\u001b[0m\u001b[0m                                             \n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 171ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m3 packages\u001b[0m \u001b[2min 115ms\u001b[0m\u001b[0m                               \u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.3 (from file:///home/conda/feedstock_root/build_artifacts/sympy_1728484478345/work)\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msympy\u001b[0m\u001b[2m==1.13.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorch\u001b[0m\u001b[2m==2.5.0+cpu\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchvision\u001b[0m\u001b[2m==0.20.0+cpu\u001b[0m\n",
      "\u001b[2mUsing Python 3.10.15 environment at: /home/ec2-user/anaconda3/envs/python3\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m206 packages\u001b[0m \u001b[2min 1.65s\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m107 packages\u001b[0m \u001b[2min 37.63s\u001b[0m\u001b[0m                                          \n",
      "\u001b[2mUninstalled \u001b[1m6 packages\u001b[0m \u001b[2min 231ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m107 packages\u001b[0m \u001b[2min 1.36s\u001b[0m\u001b[0m                             \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mabsl-py\u001b[0m\u001b[2m==2.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maccelerate\u001b[0m\u001b[2m==0.34.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1madagio\u001b[0m\u001b[2m==0.2.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1maiohttp-cors\u001b[0m\u001b[2m==0.7.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mantlr4-python3-runtime\u001b[0m\u001b[2m==4.9.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mappdirs\u001b[0m\u001b[2m==1.4.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mautogluon\u001b[0m\u001b[2m==1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mautogluon-common\u001b[0m\u001b[2m==1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mautogluon-core\u001b[0m\u001b[2m==1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mautogluon-features\u001b[0m\u001b[2m==1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mautogluon-multimodal\u001b[0m\u001b[2m==1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mautogluon-tabular\u001b[0m\u001b[2m==1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mautogluon-timeseries\u001b[0m\u001b[2m==1.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mblis\u001b[0m\u001b[2m==0.7.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcatalogue\u001b[0m\u001b[2m==2.0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcatboost\u001b[0m\u001b[2m==1.2.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcloudpathlib\u001b[0m\u001b[2m==0.20.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcolorful\u001b[0m\u001b[2m==0.5.6\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcolorlog\u001b[0m\u001b[2m==6.9.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mconfection\u001b[0m\u001b[2m==0.1.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcoreforecast\u001b[0m\u001b[2m==0.0.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mcymem\u001b[0m\u001b[2m==2.0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdatasets\u001b[0m\u001b[2m==2.14.4\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.3.9 (from file:///home/conda/feedstock_root/build_artifacts/dill_1727594984357/work)\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdill\u001b[0m\u001b[2m==0.3.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mdistlib\u001b[0m\u001b[2m==0.3.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1meinops\u001b[0m\u001b[2m==0.8.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mevaluate\u001b[0m\u001b[2m==0.4.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastai\u001b[0m\u001b[2m==2.7.18\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastcore\u001b[0m\u001b[2m==1.7.22\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastdownload\u001b[0m\u001b[2m==0.0.7\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastprogress\u001b[0m\u001b[2m==1.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfs\u001b[0m\u001b[2m==2.4.16\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfugue\u001b[0m\u001b[2m==0.9.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgdown\u001b[0m\u001b[2m==5.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgluonts\u001b[0m\u001b[2m==0.16.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogle-api-core\u001b[0m\u001b[2m==2.23.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgoogleapis-common-protos\u001b[0m\u001b[2m==1.66.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgraphviz\u001b[0m\u001b[2m==0.20.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mgrpcio\u001b[0m\u001b[2m==1.68.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhuggingface-hub\u001b[0m\u001b[2m==0.26.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mhyperopt\u001b[0m\u001b[2m==0.2.7\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mjsonschema\u001b[0m\u001b[2m==4.23.0 (from file:///home/conda/feedstock_root/build_artifacts/jsonschema_1720529478715/work)\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mjsonschema\u001b[0m\u001b[2m==4.21.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlangcodes\u001b[0m\u001b[2m==3.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlanguage-data\u001b[0m\u001b[2m==1.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlightgbm\u001b[0m\u001b[2m==4.5.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlightning\u001b[0m\u001b[2m==2.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlightning-utilities\u001b[0m\u001b[2m==0.11.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mlinkify-it-py\u001b[0m\u001b[2m==2.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmarisa-trie\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmdit-py-plugins\u001b[0m\u001b[2m==0.4.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmemray\u001b[0m\u001b[2m==1.15.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmlforecast\u001b[0m\u001b[2m==0.13.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmodel-index\u001b[0m\u001b[2m==0.1.11\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.17\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmultiprocess\u001b[0m\u001b[2m==0.70.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mmurmurhash\u001b[0m\u001b[2m==1.0.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnlpaug\u001b[0m\u001b[2m==1.1.11\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mnltk\u001b[0m\u001b[2m==3.9.1 (from file:///home/conda/feedstock_root/build_artifacts/nltk_1724022741962/work)\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnltk\u001b[0m\u001b[2m==3.8.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mnvidia-ml-py3\u001b[0m\u001b[2m==7.352.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1momegaconf\u001b[0m\u001b[2m==2.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopencensus\u001b[0m\u001b[2m==0.11.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopencensus-context\u001b[0m\u001b[2m==0.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopendatalab\u001b[0m\u001b[2m==0.0.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenmim\u001b[0m\u001b[2m==0.3.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mopenxlab\u001b[0m\u001b[2m==0.0.11\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1moptuna\u001b[0m\u001b[2m==4.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mordered-set\u001b[0m\u001b[2m==4.1.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1morjson\u001b[0m\u001b[2m==3.10.12\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==1.5.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpandas\u001b[0m\u001b[2m==2.2.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpdf2image\u001b[0m\u001b[2m==1.17.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpreshed\u001b[0m\u001b[2m==3.0.9\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mproto-plus\u001b[0m\u001b[2m==1.25.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpy-spy\u001b[0m\u001b[2m==0.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytesseract\u001b[0m\u001b[2m==0.3.10\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytorch-lightning\u001b[0m\u001b[2m==2.4.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpytorch-metric-learning\u001b[0m\u001b[2m==2.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mray\u001b[0m\u001b[2m==2.39.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msafetensors\u001b[0m\u001b[2m==0.4.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msentencepiece\u001b[0m\u001b[2m==0.2.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mseqeval\u001b[0m\u001b[2m==1.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mshellingham\u001b[0m\u001b[2m==1.5.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msmart-open\u001b[0m\u001b[2m==7.0.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy\u001b[0m\u001b[2m==3.7.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy-legacy\u001b[0m\u001b[2m==3.0.12\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mspacy-loggers\u001b[0m\u001b[2m==1.0.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1msrsly\u001b[0m\u001b[2m==2.4.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mstatsforecast\u001b[0m\u001b[2m==1.7.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtensorboard\u001b[0m\u001b[2m==2.18.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtensorboard-data-server\u001b[0m\u001b[2m==0.7.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtensorboardx\u001b[0m\u001b[2m==2.6.2.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtextual\u001b[0m\u001b[2m==0.88.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mthinc\u001b[0m\u001b[2m==8.2.5\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtimm\u001b[0m\u001b[2m==1.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtokenizers\u001b[0m\u001b[2m==0.20.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mtoolz\u001b[0m\u001b[2m==1.0.0 (from file:///home/conda/feedstock_root/build_artifacts/toolz_1728059506884/work)\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtoolz\u001b[0m\u001b[2m==0.12.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtorchmetrics\u001b[0m\u001b[2m==1.2.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtransformers\u001b[0m\u001b[2m==4.46.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtriad\u001b[0m\u001b[2m==0.9.8\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtyper\u001b[0m\u001b[2m==0.15.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mtzdata\u001b[0m\u001b[2m==2024.2\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1muc-micro-py\u001b[0m\u001b[2m==1.0.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mutilsforecast\u001b[0m\u001b[2m==0.2.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mvirtualenv\u001b[0m\u001b[2m==20.28.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwasabi\u001b[0m\u001b[2m==1.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mweasel\u001b[0m\u001b[2m==0.4.1\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mwindow-ops\u001b[0m\u001b[2m==0.0.15\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mxgboost\u001b[0m\u001b[2m==2.1.3\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mxxhash\u001b[0m\u001b[2m==3.5.0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -q uv\n",
    "# Use CPU version of PyTorch for faster installation\n",
    "!uv pip install torch==2.5 torchvision --index-url https://download.pytorch.org/whl/cpu\n",
    "!uv pip install autogluon==1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15db053578cb4911",
   "metadata": {},
   "source": [
    "## TabularPredictor\n",
    "\n",
    "To start, import AutoGluon's [TabularPredictor](https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.html) and [TabularDataset](https://auto.gluon.ai/stable/api/autogluon.core.TabularDataset.html) classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b48e2768",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef2fc39",
   "metadata": {},
   "source": [
    "Load training data from a [CSV file](https://en.wikipedia.org/wiki/Comma-separated_values) into an AutoGluon Dataset object. This object is a [Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) and the same methods can be applied to both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "671f5ff7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54860</td>\n",
       "      <td>15701364</td>\n",
       "      <td>Hsueh</td>\n",
       "      <td>635</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166515.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>160522</td>\n",
       "      <td>15634974</td>\n",
       "      <td>Nwoye</td>\n",
       "      <td>697</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143671.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56439</td>\n",
       "      <td>15706810</td>\n",
       "      <td>Smith</td>\n",
       "      <td>577</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>3</td>\n",
       "      <td>153639.11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>171519.06</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144732</td>\n",
       "      <td>15783526</td>\n",
       "      <td>Okechukwu</td>\n",
       "      <td>756</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>143393.24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134400</td>\n",
       "      <td>15641416</td>\n",
       "      <td>Chiabuotu</td>\n",
       "      <td>613</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3</td>\n",
       "      <td>96381.68</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>138871.12</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>36050</td>\n",
       "      <td>15765322</td>\n",
       "      <td>Onyekachi</td>\n",
       "      <td>559</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>82870.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2789</td>\n",
       "      <td>15674929</td>\n",
       "      <td>K?</td>\n",
       "      <td>681</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7</td>\n",
       "      <td>87866.84</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57858.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>55968</td>\n",
       "      <td>15589488</td>\n",
       "      <td>H?</td>\n",
       "      <td>713</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>34.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>166720.28</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>99054</td>\n",
       "      <td>15676519</td>\n",
       "      <td>George</td>\n",
       "      <td>615</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>61.0</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>150227.85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>87095</td>\n",
       "      <td>15611985</td>\n",
       "      <td>P'eng</td>\n",
       "      <td>613</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>8</td>\n",
       "      <td>145988.11</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>944.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id  CustomerId    Surname  CreditScore Geography  Gender   Age  \\\n",
       "0     54860    15701364      Hsueh          635    France    Male  38.0   \n",
       "1    160522    15634974      Nwoye          697    France    Male  44.0   \n",
       "2     56439    15706810      Smith          577   Germany    Male  39.0   \n",
       "3    144732    15783526  Okechukwu          756    France  Female  34.0   \n",
       "4    134400    15641416  Chiabuotu          613   Germany  Female  32.0   \n",
       "..      ...         ...        ...          ...       ...     ...   ...   \n",
       "995   36050    15765322  Onyekachi          559    France    Male  28.0   \n",
       "996    2789    15674929         K?          681    France  Female  29.0   \n",
       "997   55968    15589488         H?          713    France  Female  34.0   \n",
       "998   99054    15676519     George          615    France    Male  61.0   \n",
       "999   87095    15611985      P'eng          613    France  Female  33.0   \n",
       "\n",
       "     Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0         5       0.00              1        1.0             1.0   \n",
       "1         6       0.00              2        1.0             0.0   \n",
       "2         3  153639.11              2        0.0             1.0   \n",
       "3         7       0.00              2        1.0             0.0   \n",
       "4         3   96381.68              1        1.0             1.0   \n",
       "..      ...        ...            ...        ...             ...   \n",
       "995       0       0.00              2        1.0             1.0   \n",
       "996       7   87866.84              1        1.0             1.0   \n",
       "997      10       0.00              2        1.0             0.0   \n",
       "998       9       0.00              2        0.0             0.0   \n",
       "999       8  145988.11              1        0.0             1.0   \n",
       "\n",
       "     EstimatedSalary  Exited  \n",
       "0          166515.96       0  \n",
       "1          143671.54       0  \n",
       "2          171519.06       0  \n",
       "3          143393.24       0  \n",
       "4          138871.12       0  \n",
       "..               ...     ...  \n",
       "995         82870.75       0  \n",
       "996         57858.25       0  \n",
       "997        166720.28       0  \n",
       "998        150227.85       0  \n",
       "999           944.81       0  \n",
       "\n",
       "[1000 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/bank_churn/train.csv')\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac3f9f5",
   "metadata": {},
   "source": [
    "Note that we loaded data from a CSV file stored in the cloud. You can also specify a local file-path instead if you have already downloaded the CSV file to your own machine (e.g., using [wget](https://www.gnu.org/software/wget/)).\n",
    "Each row in the table `train_data` corresponds to a single training example. In this particular dataset, each row corresponds to an individual person, and the columns contain various characteristics related to their bank account.\n",
    "\n",
    "Let's first use these features to predict whether the person has left the bank, which is recorded in the `Exited` column of this table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fbae4f4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique classes: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "label = 'Exited'\n",
    "print(f\"Unique classes: {list(train_data[label].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2808c11",
   "metadata": {},
   "source": [
    "AutoGluon works with raw data, meaning you don't need to perform any data preprocessing before fitting AutoGluon. We actively recommend that you avoid performing operations such as missing value imputation or one-hot-encoding, as AutoGluon has dedicated logic to handle these situations automatically. You can learn more about AutoGluon's preprocessing in the [Feature Engineering Tutorial](https://auto.gluon.ai/stable/tutorials/tabular/tabular-feature-engineering.html).\n",
    "\n",
    "> **Note**: In this tutorial we will use a synthetic dataset for demonstration purposes. For this reason, we recommend focusing on the functionality and not the specific scores achieved by different models. For examples of AutoGluon's performance \"in the wild\", see [this page](https://github.com/autogluon/autogluon/blob/master/AWESOME.md#competition-solutions-using-autogluon).\n",
    "\n",
    "### Training\n",
    "\n",
    "Now we initialize and fit AutoGluon's TabularPredictor in one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93ed52d4",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241203_235857\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Oct 23 17:17:00 UTC 2024\n",
      "CPU Count:          16\n",
      "Memory Avail:       59.35 GB / 61.79 GB (96.0%)\n",
      "Disk Space Avail:   74.55 GB / 78.56 GB (94.9%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"/home/ec2-user/SageMaker/autogluon-workshops/2024-reinvent/tabular/AutogluonModels/ag-20241203_235857\"\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 13\n",
      "Label Column:       Exited\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    60766.01 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 5 | ['Age', 'Balance', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
      "\t\t('int', [])    : 5 | ['id', 'CustomerId', 'CreditScore', 'Tenure', 'NumOfProducts']\n",
      "\t\t('object', []) : 3 | ['Surname', 'Geography', 'Gender']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 2 | ['Surname', 'Geography']\n",
      "\t\t('float', [])     : 3 | ['Age', 'Balance', 'EstimatedSalary']\n",
      "\t\t('int', [])       : 5 | ['id', 'CustomerId', 'CreditScore', 'Tenure', 'NumOfProducts']\n",
      "\t\t('int', ['bool']) : 3 | ['Gender', 'HasCrCard', 'IsActiveMember']\n",
      "\t0.0s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.07 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 13 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.71\t = Validation score   (accuracy)\n",
      "\t2.12s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.705\t = Validation score   (accuracy)\n",
      "\t0.05s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.915\t = Validation score   (accuracy)\n",
      "\t1.97s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.9\t = Validation score   (accuracy)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9\t = Validation score   (accuracy)\n",
      "\t0.59s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9\t = Validation score   (accuracy)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "\t0.91\t = Validation score   (accuracy)\n",
      "\t0.63s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.89\t = Validation score   (accuracy)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.885\t = Validation score   (accuracy)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.9\t = Validation score   (accuracy)\n",
      "\t3.96s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.9\t = Validation score   (accuracy)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.865\t = Validation score   (accuracy)\n",
      "\t5.06s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.895\t = Validation score   (accuracy)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tEnsemble Weights: {'LightGBMXT': 1.0}\n",
      "\t0.915\t = Validation score   (accuracy)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 17.34s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 69430.6 rows/s (200 batch size)\n",
      "Disabling decision threshold calibration for metric `accuracy` due to having fewer than 10000 rows of validation data for calibration, to avoid overfitting (200 rows).\n",
      "\t`accuracy` is generally not improved through threshold calibration. Force calibration via specifying `calibrate_decision_threshold=True`.\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/ec2-user/SageMaker/autogluon-workshops/2024-reinvent/tabular/AutogluonModels/ag-20241203_235857\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1088b80f",
   "metadata": {},
   "source": [
    "That's it! We now have a TabularPredictor that is able to make predictions on new data.\n",
    "\n",
    "### Prediction\n",
    "\n",
    "Next, we can load a separate test data to demonstrate how to make predictions on new examples at inference time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38907743",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: https://autogluon.s3.amazonaws.com/datasets/bank_churn/test.csv | Columns = 14 / 14 | Rows = 8000 -> 8000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1934</td>\n",
       "      <td>15667938</td>\n",
       "      <td>Chikezie</td>\n",
       "      <td>539</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60552.44</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35397</td>\n",
       "      <td>15661591</td>\n",
       "      <td>Dilke</td>\n",
       "      <td>652</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>43.0</td>\n",
       "      <td>9</td>\n",
       "      <td>142706.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108876.75</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116092</td>\n",
       "      <td>15778196</td>\n",
       "      <td>Tsou</td>\n",
       "      <td>629</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4</td>\n",
       "      <td>165931.11</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162719.39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102475</td>\n",
       "      <td>15732437</td>\n",
       "      <td>Briggs</td>\n",
       "      <td>708</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>107884.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>183487.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65633</td>\n",
       "      <td>15660147</td>\n",
       "      <td>Manna</td>\n",
       "      <td>716</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97640.20</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>21373</td>\n",
       "      <td>15689341</td>\n",
       "      <td>Yermakov</td>\n",
       "      <td>666</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55470.54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>120270</td>\n",
       "      <td>15612776</td>\n",
       "      <td>Ritchie</td>\n",
       "      <td>627</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>182494.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>74802</td>\n",
       "      <td>15606839</td>\n",
       "      <td>Toscani</td>\n",
       "      <td>633</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96940.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>94895</td>\n",
       "      <td>15676835</td>\n",
       "      <td>Yancy</td>\n",
       "      <td>637</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>37.0</td>\n",
       "      <td>9</td>\n",
       "      <td>110581.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>133537.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>64462</td>\n",
       "      <td>15741633</td>\n",
       "      <td>Fuller</td>\n",
       "      <td>566</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>32.0</td>\n",
       "      <td>10</td>\n",
       "      <td>147511.26</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159891.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  CustomerId   Surname  CreditScore Geography  Gender   Age  \\\n",
       "0       1934    15667938  Chikezie          539    France  Female  63.0   \n",
       "1      35397    15661591     Dilke          652   Germany  Female  43.0   \n",
       "2     116092    15778196      Tsou          629   Germany  Female  33.0   \n",
       "3     102475    15732437    Briggs          708   Germany    Male  31.0   \n",
       "4      65633    15660147     Manna          716    France    Male  48.0   \n",
       "...      ...         ...       ...          ...       ...     ...   ...   \n",
       "7995   21373    15689341  Yermakov          666    France  Female  37.0   \n",
       "7996  120270    15612776   Ritchie          627     Spain  Female  31.0   \n",
       "7997   74802    15606839   Toscani          633    France  Female  42.0   \n",
       "7998   94895    15676835     Yancy          637   Germany    Male  37.0   \n",
       "7999   64462    15741633    Fuller          566    France  Female  32.0   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          3       0.00              2        1.0             1.0   \n",
       "1          9  142706.10              1        0.0             0.0   \n",
       "2          4  165931.11              2        0.0             0.0   \n",
       "3          0  107884.81              1        0.0             1.0   \n",
       "4          0       0.00              2        0.0             1.0   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "7995       5       0.00              2        0.0             1.0   \n",
       "7996       6       0.00              1        1.0             0.0   \n",
       "7997       5       0.00              1        1.0             1.0   \n",
       "7998       9  110581.29              1        1.0             1.0   \n",
       "7999      10  147511.26              1        1.0             0.0   \n",
       "\n",
       "      EstimatedSalary  Exited  \n",
       "0            60552.44       0  \n",
       "1           108876.75       1  \n",
       "2           162719.39       0  \n",
       "3           183487.98       0  \n",
       "4            97640.20       0  \n",
       "...               ...     ...  \n",
       "7995         55470.54       0  \n",
       "7996        182494.78       0  \n",
       "7997         96940.40       0  \n",
       "7998        133537.53       0  \n",
       "7999        159891.03       1  \n",
       "\n",
       "[8000 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TabularDataset('https://autogluon.s3.amazonaws.com/datasets/bank_churn/test.csv')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bd6e65",
   "metadata": {},
   "source": [
    "We can now use our trained models to make predictions on the new data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "388da91b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data)\n",
    "y_pred.head()  # Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f2ea44baed01439",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.721154</td>\n",
       "      <td>0.278846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.758400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.822953</td>\n",
       "      <td>0.177047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.923047</td>\n",
       "      <td>0.076953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.925227</td>\n",
       "      <td>0.074773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1\n",
       "0  0.721154  0.278846\n",
       "1  0.241600  0.758400\n",
       "2  0.822953  0.177047\n",
       "3  0.923047  0.076953\n",
       "4  0.925227  0.074773"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_proba = predictor.predict_proba(test_data)\n",
    "y_pred_proba.head()  # Prediction Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ac16b755097c93",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Next, we can [evaluate](https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.evaluate.html) the predictor on the (labeled) test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ccfb48acf364b609",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8525,\n",
       " 'balanced_accuracy': 0.7223728105291086,\n",
       " 'mcc': 0.5142830099496976,\n",
       " 'roc_auc': 0.863386681333925,\n",
       " 'f1': 0.5877009084556254,\n",
       " 'precision': 0.7194183062446535,\n",
       " 'recall': 0.496751329001772}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec141019",
   "metadata": {},
   "source": [
    "We can also [evaluate each model individually](https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.leaderboard.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0630d00d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.915</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>1.973634</td>\n",
       "      <td>0.012424</td>\n",
       "      <td>0.002254</td>\n",
       "      <td>1.973634</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.852500</td>\n",
       "      <td>0.915</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.013561</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>2.032998</td>\n",
       "      <td>0.001137</td>\n",
       "      <td>0.000626</td>\n",
       "      <td>0.059364</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.852375</td>\n",
       "      <td>0.900</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.006659</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.281493</td>\n",
       "      <td>0.006659</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.281493</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.850875</td>\n",
       "      <td>0.900</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.074139</td>\n",
       "      <td>0.036183</td>\n",
       "      <td>0.587501</td>\n",
       "      <td>0.074139</td>\n",
       "      <td>0.036183</td>\n",
       "      <td>0.587501</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.849625</td>\n",
       "      <td>0.900</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.064119</td>\n",
       "      <td>0.036482</td>\n",
       "      <td>0.446140</td>\n",
       "      <td>0.064119</td>\n",
       "      <td>0.036482</td>\n",
       "      <td>0.446140</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.849250</td>\n",
       "      <td>0.910</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.627876</td>\n",
       "      <td>0.006660</td>\n",
       "      <td>0.002107</td>\n",
       "      <td>0.627876</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.847125</td>\n",
       "      <td>0.900</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.016810</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.214654</td>\n",
       "      <td>0.016810</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>0.214654</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.846250</td>\n",
       "      <td>0.885</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.066594</td>\n",
       "      <td>0.036728</td>\n",
       "      <td>0.453235</td>\n",
       "      <td>0.066594</td>\n",
       "      <td>0.036728</td>\n",
       "      <td>0.453235</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.846125</td>\n",
       "      <td>0.890</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.068374</td>\n",
       "      <td>0.036785</td>\n",
       "      <td>0.454847</td>\n",
       "      <td>0.068374</td>\n",
       "      <td>0.036785</td>\n",
       "      <td>0.454847</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.838125</td>\n",
       "      <td>0.895</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.011410</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.622459</td>\n",
       "      <td>0.011410</td>\n",
       "      <td>0.002365</td>\n",
       "      <td>0.622459</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.831250</td>\n",
       "      <td>0.900</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.096606</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>3.957812</td>\n",
       "      <td>0.096606</td>\n",
       "      <td>0.007030</td>\n",
       "      <td>3.957812</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>0.809625</td>\n",
       "      <td>0.865</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>5.055837</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>5.055837</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.741125</td>\n",
       "      <td>0.710</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.028842</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>2.122515</td>\n",
       "      <td>0.028842</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>2.122515</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.729625</td>\n",
       "      <td>0.705</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.045085</td>\n",
       "      <td>0.014154</td>\n",
       "      <td>0.050660</td>\n",
       "      <td>0.045085</td>\n",
       "      <td>0.014154</td>\n",
       "      <td>0.050660</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_test  score_val eval_metric  pred_time_test  \\\n",
       "0            LightGBMXT    0.852500      0.915    accuracy        0.012424   \n",
       "1   WeightedEnsemble_L2    0.852500      0.915    accuracy        0.013561   \n",
       "2              LightGBM    0.852375      0.900    accuracy        0.006659   \n",
       "3      RandomForestGini    0.850875      0.900    accuracy        0.074139   \n",
       "4      RandomForestEntr    0.849625      0.900    accuracy        0.064119   \n",
       "5              CatBoost    0.849250      0.910    accuracy        0.006660   \n",
       "6               XGBoost    0.847125      0.900    accuracy        0.016810   \n",
       "7        ExtraTreesEntr    0.846250      0.885    accuracy        0.066594   \n",
       "8        ExtraTreesGini    0.846125      0.890    accuracy        0.068374   \n",
       "9         LightGBMLarge    0.838125      0.895    accuracy        0.011410   \n",
       "10      NeuralNetFastAI    0.831250      0.900    accuracy        0.096606   \n",
       "11       NeuralNetTorch    0.809625      0.865    accuracy        0.021739   \n",
       "12       KNeighborsUnif    0.741125      0.710    accuracy        0.028842   \n",
       "13       KNeighborsDist    0.729625      0.705    accuracy        0.045085   \n",
       "\n",
       "    pred_time_val  fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0        0.002254  1.973634                 0.012424                0.002254   \n",
       "1        0.002881  2.032998                 0.001137                0.000626   \n",
       "2        0.001771  0.281493                 0.006659                0.001771   \n",
       "3        0.036183  0.587501                 0.074139                0.036183   \n",
       "4        0.036482  0.446140                 0.064119                0.036482   \n",
       "5        0.002107  0.627876                 0.006660                0.002107   \n",
       "6        0.004282  0.214654                 0.016810                0.004282   \n",
       "7        0.036728  0.453235                 0.066594                0.036728   \n",
       "8        0.036785  0.454847                 0.068374                0.036785   \n",
       "9        0.002365  0.622459                 0.011410                0.002365   \n",
       "10       0.007030  3.957812                 0.096606                0.007030   \n",
       "11       0.006185  5.055837                 0.021739                0.006185   \n",
       "12       0.015756  2.122515                 0.028842                0.015756   \n",
       "13       0.014154  0.050660                 0.045085                0.014154   \n",
       "\n",
       "    fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0            1.973634            1       True          3  \n",
       "1            0.059364            2       True         14  \n",
       "2            0.281493            1       True          4  \n",
       "3            0.587501            1       True          5  \n",
       "4            0.446140            1       True          6  \n",
       "5            0.627876            1       True          7  \n",
       "6            0.214654            1       True         11  \n",
       "7            0.453235            1       True          9  \n",
       "8            0.454847            1       True          8  \n",
       "9            0.622459            1       True         13  \n",
       "10           3.957812            1       True         10  \n",
       "11           5.055837            1       True         12  \n",
       "12           2.122515            1       True          1  \n",
       "13           0.050660            1       True          2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae35bc029d386579",
   "metadata": {},
   "source": [
    "### Loading a Trained Predictor\n",
    "\n",
    "Finally, we can load the predictor in a new session (or new machine) by calling [TabularPredictor.load()](https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.load.html) and specifying the location of the predictor artifact on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85fcbc65e9dd2cfd",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/SageMaker/autogluon-workshops/2024-reinvent/tabular/AutogluonModels/ag-20241203_235857'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.path  # The path on disk where the predictor is saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3710a0faca8d4af1",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the predictor by specifying the path it is saved to on disk.\n",
    "# You can control where it is saved to by setting the `path` parameter during init\n",
    "predictor = TabularPredictor.load(predictor.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a32a595",
   "metadata": {},
   "source": [
    "```{warning}\n",
    "\n",
    "`TabularPredictor.load()` uses the `pickle` module implicitly, which is known to be insecure. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling. Never load data that could have come from an untrusted source, or that could have been tampered with. **Only load data you trust.**\n",
    "\n",
    "```\n",
    "\n",
    "Now you're ready to try AutoGluon on your own tabular datasets!\n",
    "As long as they're stored in a popular format like CSV, you should be able to achieve strong predictive performance with just 2 lines of code:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1650bf",
   "metadata": {},
   "source": [
    "```\n",
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor(label=<variable-name>).fit(train_data=<file-name>)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b4558",
   "metadata": {},
   "source": [
    "**Note:** This simple call to [TabularPredictor.fit()](https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.fit.html) is intended for your first prototype model. In a subsequent section, we'll demonstrate how to maximize predictive performance by additionally specifying the `presets` parameter to `fit()` and the `eval_metric` parameter to `TabularPredictor()`.\n",
    "\n",
    "## Description of fit()\n",
    "\n",
    "Here we discuss what happened during `fit()`.\n",
    "\n",
    "Since there are only two possible values of the `Exited` variable, this was a binary classification problem, for which an appropriate performance metric is _accuracy_. AutoGluon automatically infers this as well as the type of each feature (i.e., which columns contain continuous numbers vs. discrete categories). AutoGluon can also automatically handle common issues like missing data and rescaling feature values.\n",
    "\n",
    "We did not specify separate validation data and so AutoGluon automatically chose a random training/validation split of the data. The data used for validation is separated from the training data and is used to determine the models and hyperparameter-values that produce the best results. Rather than just a single model, AutoGluon trains multiple models and ensembles them together to obtain superior predictive performance.\n",
    "\n",
    "By default, AutoGluon tries to fit [various types of models](https://auto.gluon.ai/stable/api/autogluon.tabular.models.html) including neural networks and tree ensembles. Each type of model has various hyperparameters, which traditionally, the user would have to specify. AutoGluon automates this process.\n",
    "\n",
    "AutoGluon automatically and iteratively tests values for hyperparameters to produce the best performance on the validation data. This involves repeatedly training models under different hyperparameter settings and evaluating their performance. This process can be computationally-intensive, so `fit()` parallelizes this process across multiple threads using [Ray](https://www.ray.io/). To control runtimes, you can specify various arguments in `fit()` such as `time_limit` as demonstrated in the subsequent **[In-Depth Tutorial](https://auto.gluon.ai/stable/tutorials/tabular/tabular-indepth.html)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f84eca",
   "metadata": {},
   "source": [
    "We can view what properties AutoGluon automatically inferred about our prediction task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4074d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  binary\n",
      "AutoGluon identified the following types of features:\n",
      "('category', [])  : 2 | ['Surname', 'Geography']\n",
      "('float', [])     : 3 | ['Age', 'Balance', 'EstimatedSalary']\n",
      "('int', [])       : 5 | ['id', 'CustomerId', 'CreditScore', 'Tenure', 'NumOfProducts']\n",
      "('int', ['bool']) : 3 | ['Gender', 'HasCrCard', 'IsActiveMember']\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fde02c",
   "metadata": {},
   "source": [
    "AutoGluon correctly recognized our prediction problem to be a **binary classification** task and decided that variables such as `Age` should be represented as numeric, whereas variables such as `Geography` should be represented as categorical objects. The `feature_metadata` attribute allows you to see the inferred data type of each predictive variable after preprocessing (this is its _raw_ dtype; some features may also be associated with additional _special_ dtypes if produced via feature-engineering, e.g. numerical representations of a datetime/text column)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0ef525a7db211",
   "metadata": {},
   "source": [
    "To transform the data into AutoGluon's internal representation, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "addae3bd40b4318a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Surname</th>\n",
       "      <th>Geography</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1934</td>\n",
       "      <td>15667938</td>\n",
       "      <td>539</td>\n",
       "      <td>0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>60552.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35397</td>\n",
       "      <td>15661591</td>\n",
       "      <td>652</td>\n",
       "      <td>0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>9</td>\n",
       "      <td>142706.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>108876.75</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116092</td>\n",
       "      <td>15778196</td>\n",
       "      <td>629</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4</td>\n",
       "      <td>165931.11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>162719.39</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102475</td>\n",
       "      <td>15732437</td>\n",
       "      <td>708</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>107884.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>183487.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65633</td>\n",
       "      <td>15660147</td>\n",
       "      <td>716</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>97640.20</td>\n",
       "      <td>94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  CustomerId  CreditScore  Gender   Age  Tenure    Balance  \\\n",
       "0    1934    15667938          539       0  63.0       3       0.00   \n",
       "1   35397    15661591          652       0  43.0       9  142706.10   \n",
       "2  116092    15778196          629       0  33.0       4  165931.11   \n",
       "3  102475    15732437          708       1  31.0       0  107884.81   \n",
       "4   65633    15660147          716       1  48.0       0       0.00   \n",
       "\n",
       "   NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary Surname Geography  \n",
       "0              2          1               1         60552.44     NaN         0  \n",
       "1              1          0               0        108876.75     NaN         1  \n",
       "2              2          0               0        162719.39     173         1  \n",
       "3              1          0               1        183487.98     NaN         1  \n",
       "4              2          0               1         97640.20      94         0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_transform = predictor.transform_features(test_data)\n",
    "test_data_transform.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a608ba782bef998",
   "metadata": {},
   "source": [
    "Notice how the data is purely numeric after pre-processing (although categorical features will still be treated as categorical downstream).\n",
    "\n",
    "To better understand our trained predictor, we can estimate the overall importance of each feature via [TabularPredictor.feature_importance()](https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.feature_importance.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "567ebed45b3ba83c",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing feature importance via permutation shuffling for 13 features using 5000 rows with 5 shuffle sets...\n",
      "\t1.14s\t= Expected runtime (0.23s per shuffle set)\n",
      "\t0.7s\t= Actual runtime (Completed 5 of 5 shuffle sets)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>stddev</th>\n",
       "      <th>p_value</th>\n",
       "      <th>n</th>\n",
       "      <th>p99_high</th>\n",
       "      <th>p99_low</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0.05544</td>\n",
       "      <td>0.004175</td>\n",
       "      <td>3.829192e-06</td>\n",
       "      <td>5</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>0.046844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NumOfProducts</th>\n",
       "      <td>0.05164</td>\n",
       "      <td>0.001936</td>\n",
       "      <td>2.366040e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>0.055626</td>\n",
       "      <td>0.047654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsActiveMember</th>\n",
       "      <td>0.02084</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>3.542068e-05</td>\n",
       "      <td>5</td>\n",
       "      <td>0.026497</td>\n",
       "      <td>0.015183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Geography</th>\n",
       "      <td>0.00472</td>\n",
       "      <td>0.002373</td>\n",
       "      <td>5.635130e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.009606</td>\n",
       "      <td>-0.000166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>0.00456</td>\n",
       "      <td>0.002027</td>\n",
       "      <td>3.664753e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>0.008733</td>\n",
       "      <td>0.000387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balance</th>\n",
       "      <td>0.00160</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>8.200984e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.005929</td>\n",
       "      <td>-0.002729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0.00112</td>\n",
       "      <td>0.001591</td>\n",
       "      <td>9.531425e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.004396</td>\n",
       "      <td>-0.002156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasCrCard</th>\n",
       "      <td>0.00100</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>6.691333e-02</td>\n",
       "      <td>5</td>\n",
       "      <td>0.003454</td>\n",
       "      <td>-0.001454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Surname</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CustomerId</th>\n",
       "      <td>-0.00064</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>9.692920e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000503</td>\n",
       "      <td>-0.001783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <td>-0.00092</td>\n",
       "      <td>0.001585</td>\n",
       "      <td>8.679576e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>-0.004183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CreditScore</th>\n",
       "      <td>-0.00136</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>9.633510e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>-0.003955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tenure</th>\n",
       "      <td>-0.00304</td>\n",
       "      <td>0.001664</td>\n",
       "      <td>9.924865e-01</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>-0.006466</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 importance    stddev       p_value  n  p99_high   p99_low\n",
       "Age                 0.05544  0.004175  3.829192e-06  5  0.064036  0.046844\n",
       "NumOfProducts       0.05164  0.001936  2.366040e-07  5  0.055626  0.047654\n",
       "IsActiveMember      0.02084  0.002747  3.542068e-05  5  0.026497  0.015183\n",
       "Geography           0.00472  0.002373  5.635130e-03  5  0.009606 -0.000166\n",
       "Gender              0.00456  0.002027  3.664753e-03  5  0.008733  0.000387\n",
       "Balance             0.00160  0.002102  8.200984e-02  5  0.005929 -0.002729\n",
       "id                  0.00112  0.001591  9.531425e-02  5  0.004396 -0.002156\n",
       "HasCrCard           0.00100  0.001192  6.691333e-02  5  0.003454 -0.001454\n",
       "Surname             0.00000  0.000000  5.000000e-01  5  0.000000  0.000000\n",
       "CustomerId         -0.00064  0.000555  9.692920e-01  5  0.000503 -0.001783\n",
       "EstimatedSalary    -0.00092  0.001585  8.679576e-01  5  0.002343 -0.004183\n",
       "CreditScore        -0.00136  0.001260  9.633510e-01  5  0.001235 -0.003955\n",
       "Tenure             -0.00304  0.001664  9.924865e-01  5  0.000386 -0.006466"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.feature_importance(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f97a2",
   "metadata": {},
   "source": [
    "The `importance` column is an estimate for the amount the evaluation metric score would drop if the feature were removed from the data.\n",
    "Negative values of `importance` mean that it is likely to improve the results if re-fit with the feature removed.\n",
    "\n",
    "When we call `predict()`, AutoGluon automatically predicts with the model that displayed the best performance on validation data (i.e. the weighted-ensemble)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79066cd8f9a34ee8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'WeightedEnsemble_L2'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.model_best"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0ca088eaf1e452",
   "metadata": {},
   "source": [
    "We can instead specify which model to use for predictions like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aab2e2",
   "metadata": {},
   "source": [
    "```\n",
    "predictor.predict(test_data, model='LightGBM')\n",
    "```\n",
    "\n",
    "You can get the list of trained models via `.leaderboard()` or `.model_names()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eaa4acf8afdf20a",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['KNeighborsUnif',\n",
       " 'KNeighborsDist',\n",
       " 'LightGBMXT',\n",
       " 'LightGBM',\n",
       " 'RandomForestGini',\n",
       " 'RandomForestEntr',\n",
       " 'CatBoost',\n",
       " 'ExtraTreesGini',\n",
       " 'ExtraTreesEntr',\n",
       " 'NeuralNetFastAI',\n",
       " 'XGBoost',\n",
       " 'NeuralNetTorch',\n",
       " 'LightGBMLarge',\n",
       " 'WeightedEnsemble_L2']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.model_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a30ee6",
   "metadata": {},
   "source": [
    "The scores of predictive performance above were based on a default evaluation metric (accuracy for binary classification). Performance in certain applications may be measured by different metrics than the ones AutoGluon optimizes for by default. If you know the metric that counts in your application, you should specify it via the `eval_metric` argument as demonstrated in the next section.\n",
    "\n",
    "## Presets\n",
    "\n",
    "AutoGluon comes with a variety of presets that can be specified in the call to `.fit` via the `presets` argument. `medium_quality` is used by default to encourage initial prototyping, but for serious usage, the other presets should be used instead.\n",
    "\n",
    "| Preset         | Model Quality                                          | Use Cases                                                                                                                                               | Fit Time (Ideal) | Inference Time (Relative to medium_quality) | Disk Usage |\n",
    "| :------------- |:-------------------------------------------------------| :------------------------------------------------------------------------------------------------------------------------------------------------------ |:-----------------| :------------------------------------------ | :--------- |\n",
    "| best_quality   | State-of-the-art (SOTA), much better than high_quality | When accuracy is what matters                                                                                                                           | 16x+             | 32x+                                        | 16x+       |\n",
    "| high_quality   | Better than good_quality                               | When a very powerful, portable solution with fast inference is required: Large-scale batch inference                                                    | 16x+             | 4x                                          | 2x         |\n",
    "| good_quality   | Stronger than any other AutoML Framework               | When a powerful, highly portable solution with very fast inference is required: Billion-scale batch inference, sub-100ms online-inference, edge-devices | 16x              | 2x                                          | 0.1x       |\n",
    "| medium_quality | Competitive with other top AutoML Frameworks           | Initial prototyping, establishing a performance baseline                                                                                                | 1x               | 1x                                          | 1x         |\n",
    "\n",
    "We recommend users to start with `medium_quality` to get a sense of the problem and identify any data related issues. If `medium_quality` is taking too long to train, consider subsampling the training data during this prototyping phase.  \n",
    "Once you are comfortable, next try `best_quality`. Make sure to specify at least 16x the `time_limit` value as used in `medium_quality`. Once finished, you should have a very powerful solution that is often stronger than `medium_quality`.  \n",
    "Make sure to consider holding out test data that AutoGluon never sees during training to ensure that the models are performing as expected in terms of performance.  \n",
    "Once you evaluate both `best_quality` and `medium_quality`, check if either satisfies your needs. If neither do, consider trying `high_quality` and/or `good_quality`.  \n",
    "If none of the presets satisfy requirements, refer to [Predicting Columns in a Table - In Depth](https://auto.gluon.ai/stable/tutorials/tabular/tabular-indepth.html) for more advanced AutoGluon options.\n",
    "\n",
    "## Maximizing predictive performance\n",
    "\n",
    "**Note:** You should not call `fit()` with entirely default arguments if you are benchmarking AutoGluon-Tabular or hoping to maximize its accuracy!\n",
    "To get the best predictive accuracy with AutoGluon, you should generally use it like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "358b121a",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20241204_000252\"\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Oct 23 17:17:00 UTC 2024\n",
      "CPU Count:          16\n",
      "Memory Avail:       58.89 GB / 61.79 GB (95.3%)\n",
      "Disk Space Avail:   74.52 GB / 78.56 GB (94.8%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=1, num_bag_folds=8, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 30s of the 120s of remaining time (25%).\n",
      "\tRunning DyStack sub-fit in a ray process to avoid memory leakage. Enabling ray logging (enable_ray_logging=True). Specify `ds_args={'enable_ray_logging': False}` if you experience logging issues.\n",
      "2024-12-04 00:02:54,141\tINFO worker.py:1810 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "\t\tContext path: \"/home/ec2-user/SageMaker/autogluon-workshops/2024-reinvent/tabular/AutogluonModels/ag-20241204_000252/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Running DyStack sub-fit ...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Beginning AutoGluon training ... Time limit = 27s\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m AutoGluon will save models to \"/home/ec2-user/SageMaker/autogluon-workshops/2024-reinvent/tabular/AutogluonModels/ag-20241204_000252/ds_sub_fit/sub_fit_ho\"\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Train Data Rows:    888\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Train Data Columns: 13\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Label Column:       Exited\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Problem Type:       binary\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Preprocessing data ...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Using Feature Generators to preprocess the data ...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting AutoMLPipelineFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tAvailable Memory:                    59139.18 MB\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tTrain Data (Original)  Memory Usage: 0.23 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tStage 1 Generators:\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\tFitting AsTypeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tStage 2 Generators:\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\tFitting FillNaFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tStage 3 Generators:\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\tFitting IdentityFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\tFitting CategoryFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tStage 4 Generators:\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\tFitting DropUniqueFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tStage 5 Generators:\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tTypes of features in original data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\t('float', [])  : 5 | ['Age', 'Balance', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\t('int', [])    : 5 | ['id', 'CustomerId', 'CreditScore', 'Tenure', 'NumOfProducts']\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\t('object', []) : 3 | ['Surname', 'Geography', 'Gender']\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\t('category', [])  : 2 | ['Surname', 'Geography']\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\t('float', [])     : 3 | ['Age', 'Balance', 'EstimatedSalary']\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\t('int', [])       : 5 | ['id', 'CustomerId', 'CreditScore', 'Tenure', 'NumOfProducts']\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t\t('int', ['bool']) : 3 | ['Gender', 'HasCrCard', 'IsActiveMember']\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.0s = Fit runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t13 features in original data used to generate 13 features in processed data.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Data preprocessing and feature engineering runtime = 0.05s ...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tTo change this, specify the eval_metric parameter of Predictor()\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m User-specified model hyperparameters to be fit:\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m {\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m }\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 18.15s of the 27.23s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.5475\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 16.94s of the 26.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.5621\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.0s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.01s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 16.89s of the 25.96s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8752\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t1.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: LightGBM_BAG_L1 ... Training model for up to 14.68s of the 23.76s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8579\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t1.02s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 12.27s of the 21.35s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8663\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.58s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 11.53s of the 20.61s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8659\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.06s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: CatBoost_BAG_L1 ... Training model for up to 10.95s of the 20.02s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_ray_fit pid=27981)\u001b[0m /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "\u001b[36m(_ray_fit pid=27981)\u001b[0m Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "\u001b[36m(_ray_fit pid=27981)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8791\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t2.16s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.02s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 7.65s of the 16.72s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8664\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 7.04s of the 16.12s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8602\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.45s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 6.47s of the 15.54s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\u001b[36m(_ray_fit pid=28758)\u001b[0m No improvement since epoch 7: early stopping\n",
      "\u001b[36m(_ray_fit pid=27980)\u001b[0m /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=27980)\u001b[0m Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=27980)\u001b[0m   warnings.warn(\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8063\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t3.38s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.08s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: XGBoost_BAG_L1 ... Training model for up to 1.94s of the 11.01s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8499\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.73s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.05s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: WeightedEnsemble_L2 ... Training model for up to 27.23s of the 8.85s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.55, 'LightGBMXT_BAG_L1': 0.15, 'ExtraTreesGini_BAG_L1': 0.15, 'KNeighborsDist_BAG_L1': 0.05, 'RandomForestGini_BAG_L1': 0.05, 'NeuralNetFastAI_BAG_L1': 0.05}\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8832\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.04s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 8.74s of the 8.71s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8703\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.93s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: LightGBM_BAG_L2 ... Training model for up to 6.61s of the 6.58s of remaining time.\n",
      "\u001b[36m(_ray_fit pid=28763)\u001b[0m No improvement since epoch 7: early stopping\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=29412)\u001b[0m /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=29412)\u001b[0m Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_ray_fit pid=29412)\u001b[0m   warnings.warn(\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8646\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t1.15s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 4.05s of the 4.03s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.841\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.55s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 3.36s of the 3.33s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.851\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.46s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.07s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: CatBoost_BAG_L2 ... Training model for up to 2.77s of the 2.75s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\u001b[36m(_ray_fit pid=30884)\u001b[0m /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "\u001b[36m(_ray_fit pid=30884)\u001b[0m Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "\u001b[36m(_ray_fit pid=30884)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_ray_fit pid=30887)\u001b[0m /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/xgboost/core.py:265: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc 2.28+) to use future versions of XGBoost.\n",
      "\u001b[36m(_ray_fit pid=30887)\u001b[0m Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "\u001b[36m(_ray_fit pid=30887)\u001b[0m   warnings.warn(\n",
      "\u001b[36m(_ray_fit pid=30884)\u001b[0m \tRan out of time, early stopping on iteration 464.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8747\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t2.18s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.03s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Fitting model: WeightedEnsemble_L3 ... Training model for up to 27.23s of the -0.66s of remaining time.\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \tEnsemble Weights: {'CatBoost_BAG_L1': 0.55, 'LightGBMXT_BAG_L1': 0.15, 'ExtraTreesGini_BAG_L1': 0.15, 'KNeighborsDist_BAG_L1': 0.05, 'RandomForestGini_BAG_L1': 0.05, 'NeuralNetFastAI_BAG_L1': 0.05}\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.8832\t = Validation score   (roc_auc)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.06s\t = Training   runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m \t0.0s\t = Validation runtime\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m AutoGluon training complete, total runtime = 28.09s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 754.5 rows/s (111 batch size)\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/ec2-user/SageMaker/autogluon-workshops/2024-reinvent/tabular/AutogluonModels/ag-20241204_000252/ds_sub_fit/sub_fit_ho\")\n",
      "\u001b[36m(_dystack pid=25814)\u001b[0m Deleting DyStack predictor artifacts (clean_up_fits=True) ...\n",
      "Leaderboard on holdout data (DyStack):\n",
      "                      model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0           CatBoost_BAG_L1       0.901042   0.879134     roc_auc        0.349481       0.021590   2.156119                 0.349481                0.021590           2.156119            1       True          7\n",
      "1       WeightedEnsemble_L2       0.898674   0.883169     roc_auc        1.371941       0.276919   7.681720                 0.002204                0.000510           0.042230            2       True         12\n",
      "2       WeightedEnsemble_L3       0.898674   0.883169     roc_auc        1.372015       0.277099   7.702489                 0.002278                0.000689           0.062999            3       True         18\n",
      "3           CatBoost_BAG_L2       0.894413   0.874734     roc_auc        1.450182       0.351894  10.550281                 0.016243                0.027616           2.181978            2       True         17\n",
      "4   RandomForestGini_BAG_L2       0.891809   0.840999     roc_auc        1.478983       0.390329   8.922394                 0.045044                0.066050           0.554091            2       True         15\n",
      "5     ExtraTreesGini_BAG_L1       0.891809   0.866398     roc_auc        0.050077       0.067185   0.454811                 0.050077                0.067185           0.454811            1       True          8\n",
      "6   RandomForestGini_BAG_L1       0.888258   0.866311     roc_auc        0.046921       0.066387   0.582802                 0.046921                0.066387           0.582802            1       True          5\n",
      "7   RandomForestEntr_BAG_L1       0.886600   0.865874     roc_auc        0.043612       0.064883   0.460295                 0.043612                0.064883           0.460295            1       True          6\n",
      "8         LightGBMXT_BAG_L2       0.885417   0.870304     roc_auc        1.453847       0.353464   9.303197                 0.019907                0.029185           0.934894            2       True         13\n",
      "9   RandomForestEntr_BAG_L2       0.881629   0.851007     roc_auc        1.481869       0.389977   8.828217                 0.047930                0.065698           0.459914            2       True         16\n",
      "10          LightGBM_BAG_L1       0.881629   0.857918     roc_auc        0.016998       0.025565   1.017956                 0.016998                0.025565           1.017956            1       True          4\n",
      "11          LightGBM_BAG_L2       0.877367   0.864620     roc_auc        1.453040       0.351835   9.515466                 0.019100                0.027556           1.147163            2       True         14\n",
      "12        LightGBMXT_BAG_L1       0.870739   0.875198     roc_auc        0.556663       0.024291   1.060385                 0.556663                0.024291           1.060385            1       True          3\n",
      "13    ExtraTreesEntr_BAG_L1       0.870265   0.860228     roc_auc        0.048533       0.066803   0.451942                 0.048533                0.066803           0.451942            1       True          9\n",
      "14           XGBoost_BAG_L1       0.864583   0.849867     roc_auc        0.064203       0.047869   0.728813                 0.064203                0.047869           0.728813            1       True         11\n",
      "15   NeuralNetFastAI_BAG_L1       0.789773   0.806345     roc_auc        0.349573       0.082683   3.380934                 0.349573                0.082683           3.380934            1       True         10\n",
      "16    KNeighborsDist_BAG_L1       0.555398   0.562112     roc_auc        0.017021       0.014274   0.004440                 0.017021                0.014274           0.004440            1       True          2\n",
      "17    KNeighborsUnif_BAG_L1       0.535511   0.547470     roc_auc        0.017296       0.015526   0.004345                 0.017296                0.015526           0.004345            1       True          1\n",
      "\t1\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: False)\n",
      "\t34s\t = DyStack   runtime |\t86s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=1.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=1)`\n",
      "Beginning AutoGluon training ... Time limit = 86s\n",
      "AutoGluon will save models to \"/home/ec2-user/SageMaker/autogluon-workshops/2024-reinvent/tabular/AutogluonModels/ag-20241204_000252\"\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 13\n",
      "Label Column:       Exited\n",
      "Problem Type:       binary\n",
      "Preprocessing data ...\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    59428.13 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 3 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 5 | ['Age', 'Balance', 'HasCrCard', 'IsActiveMember', 'EstimatedSalary']\n",
      "\t\t('int', [])    : 5 | ['id', 'CustomerId', 'CreditScore', 'Tenure', 'NumOfProducts']\n",
      "\t\t('object', []) : 3 | ['Surname', 'Geography', 'Gender']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 2 | ['Surname', 'Geography']\n",
      "\t\t('float', [])     : 3 | ['Age', 'Balance', 'EstimatedSalary']\n",
      "\t\t('int', [])       : 5 | ['id', 'CustomerId', 'CreditScore', 'Tenure', 'NumOfProducts']\n",
      "\t\t('int', ['bool']) : 3 | ['Gender', 'HasCrCard', 'IsActiveMember']\n",
      "\t0.1s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.07 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'roc_auc'\n",
      "\tThis metric expects predicted probabilities rather than predicted class labels, so you'll need to use predict_proba() instead of predict()\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Large model count detected (112 configs) ... Only displaying the first 3 models of each family. To see all, set `verbosity=3`.\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}, {'activation': 'elu', 'dropout_prob': 0.10077639529843717, 'hidden_size': 108, 'learning_rate': 0.002735937344002146, 'num_layers': 4, 'use_batchnorm': True, 'weight_decay': 1.356433327634438e-12, 'ag_args': {'name_suffix': '_r79', 'priority': -2}}, {'activation': 'elu', 'dropout_prob': 0.11897478034205347, 'hidden_size': 213, 'learning_rate': 0.0010474382260641949, 'num_layers': 4, 'use_batchnorm': False, 'weight_decay': 5.594471067786272e-10, 'ag_args': {'name_suffix': '_r22', 'priority': -7}}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}, {'depth': 6, 'grow_policy': 'SymmetricTree', 'l2_leaf_reg': 2.1542798306067823, 'learning_rate': 0.06864209415792857, 'max_ctr_complexity': 4, 'one_hot_max_size': 10, 'ag_args': {'name_suffix': '_r177', 'priority': -1}}, {'depth': 8, 'grow_policy': 'Depthwise', 'l2_leaf_reg': 2.7997999596449104, 'learning_rate': 0.031375015734637225, 'max_ctr_complexity': 2, 'one_hot_max_size': 3, 'ag_args': {'name_suffix': '_r9', 'priority': -5}}],\n",
      "\t'XGB': [{}, {'colsample_bytree': 0.6917311125174739, 'enable_categorical': False, 'learning_rate': 0.018063876087523967, 'max_depth': 10, 'min_child_weight': 0.6028633586934382, 'ag_args': {'name_suffix': '_r33', 'priority': -8}}, {'colsample_bytree': 0.6628423832084077, 'enable_categorical': False, 'learning_rate': 0.08775715546881824, 'max_depth': 5, 'min_child_weight': 0.6294123374222513, 'ag_args': {'name_suffix': '_r89', 'priority': -16}}],\n",
      "\t'FASTAI': [{}, {'bs': 256, 'emb_drop': 0.5411770367537934, 'epochs': 43, 'layers': [800, 400], 'lr': 0.01519848858318159, 'ps': 0.23782946566604385, 'ag_args': {'name_suffix': '_r191', 'priority': -4}}, {'bs': 2048, 'emb_drop': 0.05070411322605811, 'epochs': 29, 'layers': [200, 100], 'lr': 0.08974235041576624, 'ps': 0.10393466140748028, 'ag_args': {'name_suffix': '_r102', 'priority': -11}}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 110 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ... Training model for up to 57.58s of the 86.38s of remaining time.\n",
      "\t0.5382\t = Validation score   (roc_auc)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist_BAG_L1 ... Training model for up to 57.49s of the 86.29s of remaining time.\n",
      "\t0.5591\t = Validation score   (roc_auc)\n",
      "\t0.0s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 57.40s of the 86.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t0.8747\t = Validation score   (roc_auc)\n",
      "\t1.1s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 55.13s of the 83.93s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t0.8694\t = Validation score   (roc_auc)\n",
      "\t1.22s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 52.47s of the 81.27s of remaining time.\n",
      "\t0.8761\t = Validation score   (roc_auc)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 51.70s of the 80.50s of remaining time.\n",
      "\t0.8795\t = Validation score   (roc_auc)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L1 ... Training model for up to 51.08s of the 79.88s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.8883\t = Validation score   (roc_auc)\n",
      "\t2.19s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L1 ... Training model for up to 47.71s of the 76.52s of remaining time.\n",
      "\t0.874\t = Validation score   (roc_auc)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L1 ... Training model for up to 47.07s of the 75.87s of remaining time.\n",
      "\t0.8752\t = Validation score   (roc_auc)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 46.45s of the 75.26s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t0.8228\t = Validation score   (roc_auc)\n",
      "\t3.7s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L1 ... Training model for up to 41.55s of the 70.35s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.8645\t = Validation score   (roc_auc)\n",
      "\t0.69s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ... Training model for up to 39.41s of the 68.21s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t0.8084\t = Validation score   (roc_auc)\n",
      "\t6.66s\t = Training   runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L1 ... Training model for up to 31.40s of the 60.20s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.8374\t = Validation score   (roc_auc)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: CatBoost_r177_BAG_L1 ... Training model for up to 28.53s of the 57.33s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.8805\t = Validation score   (roc_auc)\n",
      "\t1.65s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_r79_BAG_L1 ... Training model for up to 25.44s of the 54.25s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t0.8503\t = Validation score   (roc_auc)\n",
      "\t6.92s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: LightGBM_r131_BAG_L1 ... Training model for up to 17.14s of the 45.95s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.872\t = Validation score   (roc_auc)\n",
      "\t1.46s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_r191_BAG_L1 ... Training model for up to 14.34s of the 43.14s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t0.8017\t = Validation score   (roc_auc)\n",
      "\t4.18s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: CatBoost_r9_BAG_L1 ... Training model for up to 8.76s of the 37.56s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.03%)\n",
      "\t0.8879\t = Validation score   (roc_auc)\n",
      "\t7.13s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM_r96_BAG_L1 ... Training model for up to 0.09s of the 28.90s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\tTime limit exceeded... Skipping LightGBM_r96_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 86.39s of the 28.50s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r9_BAG_L1': 0.48, 'NeuralNetTorch_r79_BAG_L1': 0.2, 'CatBoost_BAG_L1': 0.16, 'KNeighborsDist_BAG_L1': 0.04, 'RandomForestGini_BAG_L1': 0.04, 'ExtraTreesGini_BAG_L1': 0.04, 'NeuralNetFastAI_BAG_L1': 0.04}\n",
      "\t0.8988\t = Validation score   (roc_auc)\n",
      "\t0.08s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 108 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 28.33s of the 28.30s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.8824\t = Validation score   (roc_auc)\n",
      "\t1.03s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 26.10s of the 26.07s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.01%)\n",
      "\t0.8792\t = Validation score   (roc_auc)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L2 ... Training model for up to 23.45s of the 23.41s of remaining time.\n",
      "\t0.8758\t = Validation score   (roc_auc)\n",
      "\t0.61s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L2 ... Training model for up to 22.63s of the 22.60s of remaining time.\n",
      "\t0.8744\t = Validation score   (roc_auc)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: CatBoost_BAG_L2 ... Training model for up to 22.01s of the 21.98s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.8869\t = Validation score   (roc_auc)\n",
      "\t3.02s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini_BAG_L2 ... Training model for up to 17.81s of the 17.77s of remaining time.\n",
      "\t0.8791\t = Validation score   (roc_auc)\n",
      "\t0.46s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr_BAG_L2 ... Training model for up to 17.17s of the 17.13s of remaining time.\n",
      "\t0.8805\t = Validation score   (roc_auc)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 16.56s of the 16.52s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t0.8403\t = Validation score   (roc_auc)\n",
      "\t3.1s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: XGBoost_BAG_L2 ... Training model for up to 12.22s of the 12.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.02%)\n",
      "\t0.8776\t = Validation score   (roc_auc)\n",
      "\t0.81s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ... Training model for up to 9.82s of the 9.79s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.00%)\n",
      "\t0.8753\t = Validation score   (roc_auc)\n",
      "\t6.19s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge_BAG_L2 ... Training model for up to 2.22s of the 2.19s of remaining time.\n",
      "\tFitting 8 child models (S1F1 - S1F8) | Fitting with ParallelLocalFoldFittingStrategy (8 workers, per: cpus=2, gpus=0, memory=0.04%)\n",
      "\t0.8474\t = Validation score   (roc_auc)\n",
      "\t2.41s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 86.39s of the -1.56s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost_r9_BAG_L1': 0.375, 'NeuralNetTorch_r79_BAG_L1': 0.167, 'NeuralNetTorch_BAG_L2': 0.125, 'CatBoost_BAG_L1': 0.083, 'LightGBM_BAG_L2': 0.083, 'XGBoost_BAG_L2': 0.083, 'KNeighborsDist_BAG_L1': 0.042, 'RandomForestGini_BAG_L1': 0.042}\n",
      "\t0.9001\t = Validation score   (roc_auc)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 88.22s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 175.7 rows/s (125 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/ec2-user/SageMaker/autogluon-workshops/2024-reinvent/tabular/AutogluonModels/ag-20241204_000252\")\n"
     ]
    }
   ],
   "source": [
    "time_limit = 120  # for quick demonstration only, you should set this to longest time you are willing to wait (in seconds)\n",
    "metric = 'roc_auc'  # specify your evaluation metric here\n",
    "predictor = TabularPredictor(label, eval_metric=metric).fit(train_data, time_limit=time_limit, presets='best_quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b45474df26853911",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CatBoost_BAG_L1</td>\n",
       "      <td>0.882181</td>\n",
       "      <td>0.888265</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.042804</td>\n",
       "      <td>0.023806</td>\n",
       "      <td>2.187929</td>\n",
       "      <td>0.042804</td>\n",
       "      <td>0.023806</td>\n",
       "      <td>2.187929</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost_r177_BAG_L1</td>\n",
       "      <td>0.880098</td>\n",
       "      <td>0.880501</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.022286</td>\n",
       "      <td>0.023890</td>\n",
       "      <td>1.647939</td>\n",
       "      <td>0.022286</td>\n",
       "      <td>0.023890</td>\n",
       "      <td>1.647939</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.878246</td>\n",
       "      <td>0.898842</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>1.415036</td>\n",
       "      <td>0.352609</td>\n",
       "      <td>21.064224</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.000553</td>\n",
       "      <td>0.083542</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WeightedEnsemble_L3</td>\n",
       "      <td>0.877265</td>\n",
       "      <td>0.900093</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.587722</td>\n",
       "      <td>0.978499</td>\n",
       "      <td>44.321019</td>\n",
       "      <td>0.003213</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.092001</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost_BAG_L2</td>\n",
       "      <td>0.876691</td>\n",
       "      <td>0.886882</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>2.994690</td>\n",
       "      <td>0.798231</td>\n",
       "      <td>39.017195</td>\n",
       "      <td>0.030808</td>\n",
       "      <td>0.032226</td>\n",
       "      <td>3.019979</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CatBoost_r9_BAG_L1</td>\n",
       "      <td>0.876415</td>\n",
       "      <td>0.887894</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.057712</td>\n",
       "      <td>0.024676</td>\n",
       "      <td>7.125108</td>\n",
       "      <td>0.057712</td>\n",
       "      <td>0.024676</td>\n",
       "      <td>7.125108</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesGini_BAG_L2</td>\n",
       "      <td>0.875745</td>\n",
       "      <td>0.879145</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.033794</td>\n",
       "      <td>0.835689</td>\n",
       "      <td>36.455195</td>\n",
       "      <td>0.069912</td>\n",
       "      <td>0.069684</td>\n",
       "      <td>0.457979</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ExtraTreesEntr_BAG_L2</td>\n",
       "      <td>0.875503</td>\n",
       "      <td>0.880465</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.030683</td>\n",
       "      <td>0.835886</td>\n",
       "      <td>36.450021</td>\n",
       "      <td>0.066802</td>\n",
       "      <td>0.069880</td>\n",
       "      <td>0.452805</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LightGBMXT_BAG_L2</td>\n",
       "      <td>0.875053</td>\n",
       "      <td>0.882441</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.015293</td>\n",
       "      <td>0.793603</td>\n",
       "      <td>37.027897</td>\n",
       "      <td>0.051412</td>\n",
       "      <td>0.027598</td>\n",
       "      <td>1.030681</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NeuralNetTorch_BAG_L2</td>\n",
       "      <td>0.874786</td>\n",
       "      <td>0.875293</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.363585</td>\n",
       "      <td>0.895944</td>\n",
       "      <td>42.191571</td>\n",
       "      <td>0.399704</td>\n",
       "      <td>0.129939</td>\n",
       "      <td>6.194355</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LightGBMXT_BAG_L1</td>\n",
       "      <td>0.874219</td>\n",
       "      <td>0.874671</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.089822</td>\n",
       "      <td>0.024930</td>\n",
       "      <td>1.097151</td>\n",
       "      <td>0.089822</td>\n",
       "      <td>0.024930</td>\n",
       "      <td>1.097151</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LightGBM_r131_BAG_L1</td>\n",
       "      <td>0.873326</td>\n",
       "      <td>0.872049</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.188038</td>\n",
       "      <td>0.032537</td>\n",
       "      <td>1.460741</td>\n",
       "      <td>0.188038</td>\n",
       "      <td>0.032537</td>\n",
       "      <td>1.460741</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ExtraTreesEntr_BAG_L1</td>\n",
       "      <td>0.873210</td>\n",
       "      <td>0.875174</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.066816</td>\n",
       "      <td>0.069419</td>\n",
       "      <td>0.454394</td>\n",
       "      <td>0.066816</td>\n",
       "      <td>0.069419</td>\n",
       "      <td>0.454394</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>RandomForestEntr_BAG_L1</td>\n",
       "      <td>0.872024</td>\n",
       "      <td>0.879534</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.078432</td>\n",
       "      <td>0.068279</td>\n",
       "      <td>0.467264</td>\n",
       "      <td>0.078432</td>\n",
       "      <td>0.068279</td>\n",
       "      <td>0.467264</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LightGBM_BAG_L1</td>\n",
       "      <td>0.871458</td>\n",
       "      <td>0.869406</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.048667</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>1.219419</td>\n",
       "      <td>0.048667</td>\n",
       "      <td>0.026959</td>\n",
       "      <td>1.219419</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ExtraTreesGini_BAG_L1</td>\n",
       "      <td>0.871425</td>\n",
       "      <td>0.874012</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.068283</td>\n",
       "      <td>0.069071</td>\n",
       "      <td>0.465401</td>\n",
       "      <td>0.068283</td>\n",
       "      <td>0.069071</td>\n",
       "      <td>0.465401</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>XGBoost_BAG_L1</td>\n",
       "      <td>0.870298</td>\n",
       "      <td>0.864465</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.132621</td>\n",
       "      <td>0.049221</td>\n",
       "      <td>0.688603</td>\n",
       "      <td>0.132621</td>\n",
       "      <td>0.049221</td>\n",
       "      <td>0.688603</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>RandomForestEntr_BAG_L2</td>\n",
       "      <td>0.869399</td>\n",
       "      <td>0.874428</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.042701</td>\n",
       "      <td>0.834031</td>\n",
       "      <td>36.464231</td>\n",
       "      <td>0.078819</td>\n",
       "      <td>0.068025</td>\n",
       "      <td>0.467016</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RandomForestGini_BAG_L2</td>\n",
       "      <td>0.867839</td>\n",
       "      <td>0.875832</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.042326</td>\n",
       "      <td>0.833918</td>\n",
       "      <td>36.606969</td>\n",
       "      <td>0.078445</td>\n",
       "      <td>0.067912</td>\n",
       "      <td>0.609753</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>XGBoost_BAG_L2</td>\n",
       "      <td>0.867522</td>\n",
       "      <td>0.877574</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.131774</td>\n",
       "      <td>0.818353</td>\n",
       "      <td>36.809018</td>\n",
       "      <td>0.167892</td>\n",
       "      <td>0.052348</td>\n",
       "      <td>0.811802</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RandomForestGini_BAG_L1</td>\n",
       "      <td>0.867395</td>\n",
       "      <td>0.876071</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.076744</td>\n",
       "      <td>0.066971</td>\n",
       "      <td>0.578065</td>\n",
       "      <td>0.076744</td>\n",
       "      <td>0.066971</td>\n",
       "      <td>0.578065</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LightGBM_BAG_L2</td>\n",
       "      <td>0.866232</td>\n",
       "      <td>0.879154</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.016914</td>\n",
       "      <td>0.795621</td>\n",
       "      <td>37.222862</td>\n",
       "      <td>0.053032</td>\n",
       "      <td>0.029616</td>\n",
       "      <td>1.225646</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LightGBMLarge_BAG_L2</td>\n",
       "      <td>0.858755</td>\n",
       "      <td>0.847387</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.037678</td>\n",
       "      <td>0.796971</td>\n",
       "      <td>38.403294</td>\n",
       "      <td>0.073796</td>\n",
       "      <td>0.030965</td>\n",
       "      <td>2.406078</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>LightGBMLarge_BAG_L1</td>\n",
       "      <td>0.857582</td>\n",
       "      <td>0.837408</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.059245</td>\n",
       "      <td>0.026299</td>\n",
       "      <td>1.592339</td>\n",
       "      <td>0.059245</td>\n",
       "      <td>0.026299</td>\n",
       "      <td>1.592339</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NeuralNetFastAI_BAG_L2</td>\n",
       "      <td>0.857414</td>\n",
       "      <td>0.840263</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>3.643220</td>\n",
       "      <td>0.851454</td>\n",
       "      <td>39.099941</td>\n",
       "      <td>0.679338</td>\n",
       "      <td>0.085448</td>\n",
       "      <td>3.102726</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NeuralNetTorch_r79_BAG_L1</td>\n",
       "      <td>0.844728</td>\n",
       "      <td>0.850338</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.451954</td>\n",
       "      <td>0.066118</td>\n",
       "      <td>6.916840</td>\n",
       "      <td>0.451954</td>\n",
       "      <td>0.066118</td>\n",
       "      <td>6.916840</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NeuralNetFastAI_BAG_L1</td>\n",
       "      <td>0.830298</td>\n",
       "      <td>0.822838</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.674217</td>\n",
       "      <td>0.086889</td>\n",
       "      <td>3.702518</td>\n",
       "      <td>0.674217</td>\n",
       "      <td>0.086889</td>\n",
       "      <td>3.702518</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NeuralNetTorch_BAG_L1</td>\n",
       "      <td>0.825305</td>\n",
       "      <td>0.808406</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.194506</td>\n",
       "      <td>0.060624</td>\n",
       "      <td>6.663573</td>\n",
       "      <td>0.194506</td>\n",
       "      <td>0.060624</td>\n",
       "      <td>6.663573</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NeuralNetFastAI_r191_BAG_L1</td>\n",
       "      <td>0.820731</td>\n",
       "      <td>0.801725</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.765017</td>\n",
       "      <td>0.092382</td>\n",
       "      <td>4.179305</td>\n",
       "      <td>0.765017</td>\n",
       "      <td>0.092382</td>\n",
       "      <td>4.179305</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>KNeighborsDist_BAG_L1</td>\n",
       "      <td>0.544838</td>\n",
       "      <td>0.559091</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.040496</td>\n",
       "      <td>0.014524</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.040496</td>\n",
       "      <td>0.014524</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>KNeighborsUnif_BAG_L1</td>\n",
       "      <td>0.541976</td>\n",
       "      <td>0.538206</td>\n",
       "      <td>roc_auc</td>\n",
       "      <td>0.036418</td>\n",
       "      <td>0.016557</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.036418</td>\n",
       "      <td>0.016557</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          model  score_test  score_val eval_metric  \\\n",
       "0               CatBoost_BAG_L1    0.882181   0.888265     roc_auc   \n",
       "1          CatBoost_r177_BAG_L1    0.880098   0.880501     roc_auc   \n",
       "2           WeightedEnsemble_L2    0.878246   0.898842     roc_auc   \n",
       "3           WeightedEnsemble_L3    0.877265   0.900093     roc_auc   \n",
       "4               CatBoost_BAG_L2    0.876691   0.886882     roc_auc   \n",
       "5            CatBoost_r9_BAG_L1    0.876415   0.887894     roc_auc   \n",
       "6         ExtraTreesGini_BAG_L2    0.875745   0.879145     roc_auc   \n",
       "7         ExtraTreesEntr_BAG_L2    0.875503   0.880465     roc_auc   \n",
       "8             LightGBMXT_BAG_L2    0.875053   0.882441     roc_auc   \n",
       "9         NeuralNetTorch_BAG_L2    0.874786   0.875293     roc_auc   \n",
       "10            LightGBMXT_BAG_L1    0.874219   0.874671     roc_auc   \n",
       "11         LightGBM_r131_BAG_L1    0.873326   0.872049     roc_auc   \n",
       "12        ExtraTreesEntr_BAG_L1    0.873210   0.875174     roc_auc   \n",
       "13      RandomForestEntr_BAG_L1    0.872024   0.879534     roc_auc   \n",
       "14              LightGBM_BAG_L1    0.871458   0.869406     roc_auc   \n",
       "15        ExtraTreesGini_BAG_L1    0.871425   0.874012     roc_auc   \n",
       "16               XGBoost_BAG_L1    0.870298   0.864465     roc_auc   \n",
       "17      RandomForestEntr_BAG_L2    0.869399   0.874428     roc_auc   \n",
       "18      RandomForestGini_BAG_L2    0.867839   0.875832     roc_auc   \n",
       "19               XGBoost_BAG_L2    0.867522   0.877574     roc_auc   \n",
       "20      RandomForestGini_BAG_L1    0.867395   0.876071     roc_auc   \n",
       "21              LightGBM_BAG_L2    0.866232   0.879154     roc_auc   \n",
       "22         LightGBMLarge_BAG_L2    0.858755   0.847387     roc_auc   \n",
       "23         LightGBMLarge_BAG_L1    0.857582   0.837408     roc_auc   \n",
       "24       NeuralNetFastAI_BAG_L2    0.857414   0.840263     roc_auc   \n",
       "25    NeuralNetTorch_r79_BAG_L1    0.844728   0.850338     roc_auc   \n",
       "26       NeuralNetFastAI_BAG_L1    0.830298   0.822838     roc_auc   \n",
       "27        NeuralNetTorch_BAG_L1    0.825305   0.808406     roc_auc   \n",
       "28  NeuralNetFastAI_r191_BAG_L1    0.820731   0.801725     roc_auc   \n",
       "29        KNeighborsDist_BAG_L1    0.544838   0.559091     roc_auc   \n",
       "30        KNeighborsUnif_BAG_L1    0.541976   0.538206     roc_auc   \n",
       "\n",
       "    pred_time_test  pred_time_val   fit_time  pred_time_test_marginal  \\\n",
       "0         0.042804       0.023806   2.187929                 0.042804   \n",
       "1         0.022286       0.023890   1.647939                 0.022286   \n",
       "2         1.415036       0.352609  21.064224                 0.002825   \n",
       "3         3.587722       0.978499  44.321019                 0.003213   \n",
       "4         2.994690       0.798231  39.017195                 0.030808   \n",
       "5         0.057712       0.024676   7.125108                 0.057712   \n",
       "6         3.033794       0.835689  36.455195                 0.069912   \n",
       "7         3.030683       0.835886  36.450021                 0.066802   \n",
       "8         3.015293       0.793603  37.027897                 0.051412   \n",
       "9         3.363585       0.895944  42.191571                 0.399704   \n",
       "10        0.089822       0.024930   1.097151                 0.089822   \n",
       "11        0.188038       0.032537   1.460741                 0.188038   \n",
       "12        0.066816       0.069419   0.454394                 0.066816   \n",
       "13        0.078432       0.068279   0.467264                 0.078432   \n",
       "14        0.048667       0.026959   1.219419                 0.048667   \n",
       "15        0.068283       0.069071   0.465401                 0.068283   \n",
       "16        0.132621       0.049221   0.688603                 0.132621   \n",
       "17        3.042701       0.834031  36.464231                 0.078819   \n",
       "18        3.042326       0.833918  36.606969                 0.078445   \n",
       "19        3.131774       0.818353  36.809018                 0.167892   \n",
       "20        0.076744       0.066971   0.578065                 0.076744   \n",
       "21        3.016914       0.795621  37.222862                 0.053032   \n",
       "22        3.037678       0.796971  38.403294                 0.073796   \n",
       "23        0.059245       0.026299   1.592339                 0.059245   \n",
       "24        3.643220       0.851454  39.099941                 0.679338   \n",
       "25        0.451954       0.066118   6.916840                 0.451954   \n",
       "26        0.674217       0.086889   3.702518                 0.674217   \n",
       "27        0.194506       0.060624   6.663573                 0.194506   \n",
       "28        0.765017       0.092382   4.179305                 0.765017   \n",
       "29        0.040496       0.014524   0.004822                 0.040496   \n",
       "30        0.036418       0.016557   0.005502                 0.036418   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.023806           2.187929            1       True   \n",
       "1                 0.023890           1.647939            1       True   \n",
       "2                 0.000553           0.083542            2       True   \n",
       "3                 0.000591           0.092001            3       True   \n",
       "4                 0.032226           3.019979            2       True   \n",
       "5                 0.024676           7.125108            1       True   \n",
       "6                 0.069684           0.457979            2       True   \n",
       "7                 0.069880           0.452805            2       True   \n",
       "8                 0.027598           1.030681            2       True   \n",
       "9                 0.129939           6.194355            2       True   \n",
       "10                0.024930           1.097151            1       True   \n",
       "11                0.032537           1.460741            1       True   \n",
       "12                0.069419           0.454394            1       True   \n",
       "13                0.068279           0.467264            1       True   \n",
       "14                0.026959           1.219419            1       True   \n",
       "15                0.069071           0.465401            1       True   \n",
       "16                0.049221           0.688603            1       True   \n",
       "17                0.068025           0.467016            2       True   \n",
       "18                0.067912           0.609753            2       True   \n",
       "19                0.052348           0.811802            2       True   \n",
       "20                0.066971           0.578065            1       True   \n",
       "21                0.029616           1.225646            2       True   \n",
       "22                0.030965           2.406078            2       True   \n",
       "23                0.026299           1.592339            1       True   \n",
       "24                0.085448           3.102726            2       True   \n",
       "25                0.066118           6.916840            1       True   \n",
       "26                0.086889           3.702518            1       True   \n",
       "27                0.060624           6.663573            1       True   \n",
       "28                0.092382           4.179305            1       True   \n",
       "29                0.014524           0.004822            1       True   \n",
       "30                0.016557           0.005502            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           7  \n",
       "1          14  \n",
       "2          19  \n",
       "3          31  \n",
       "4          24  \n",
       "5          18  \n",
       "6          25  \n",
       "7          26  \n",
       "8          20  \n",
       "9          29  \n",
       "10          3  \n",
       "11         16  \n",
       "12          9  \n",
       "13          6  \n",
       "14          4  \n",
       "15          8  \n",
       "16         11  \n",
       "17         23  \n",
       "18         22  \n",
       "19         28  \n",
       "20          5  \n",
       "21         21  \n",
       "22         30  \n",
       "23         13  \n",
       "24         27  \n",
       "25         15  \n",
       "26         10  \n",
       "27         12  \n",
       "28         17  \n",
       "29          2  \n",
       "30          1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8a57a7",
   "metadata": {},
   "source": [
    "This command implements the following strategy to maximize accuracy:\n",
    "\n",
    "- Specify the argument `presets='best_quality'`, which allows AutoGluon to automatically construct powerful model ensembles based on [stacking/bagging](https://arxiv.org/abs/2003.06505), and will greatly improve the resulting predictions if granted sufficient training time. The default value of `presets` is `'medium_quality'`, which produces _less_ accurate models but facilitates faster prototyping. With `presets`, you can flexibly prioritize predictive accuracy vs. training/inference speed. For example, if you care less about predictive performance and want to quickly deploy a basic model, consider using: `presets=['good_quality', 'optimize_for_deployment']`.\n",
    "\n",
    "- Provide the parameter `eval_metric` to `TabularPredictor()` if you know what metric will be used to evaluate predictions in your application. Some other non-default metrics you might use include things like: `'f1'` (for binary classification), `'roc_auc'` (for binary classification), `'log_loss'` (for classification), `'mean_absolute_error'` (for regression), `'median_absolute_error'` (for regression). You can also define your own custom metric function. For more information refer to [Adding a custom metric to AutoGluon](https://auto.gluon.ai/stable/tutorials/tabular/advanced/tabular-custom-metric.html).\n",
    "\n",
    "- Include all your data in `train_data` and do not provide `tuning_data` (AutoGluon will split the data more intelligently to fit its needs).\n",
    "\n",
    "- Do not specify the `hyperparameter_tune_kwargs` argument (counterintuitively, hyperparameter tuning is not the best way to spend a limited training time budgets, as model ensembling is often superior). We recommend you only use `hyperparameter_tune_kwargs` if your goal is to deploy a single model rather than an ensemble.\n",
    "\n",
    "- Do not specify the `hyperparameters` argument (allow AutoGluon to adaptively select which models/hyperparameters to use).\n",
    "\n",
    "- Set `time_limit` to the longest amount of time (in seconds) that you are willing to wait. AutoGluon's predictive performance improves the longer `fit()` is allowed to run.\n",
    "\n",
    "## Regression (predicting numeric table columns):\n",
    "\n",
    "To demonstrate that `fit()` can also automatically handle regression tasks, we now try to predict the numeric `EstimatedSalary` variable in the same table based on the other features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce850e3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    166515.96\n",
       "1    143671.54\n",
       "2    171519.06\n",
       "3    143393.24\n",
       "4    138871.12\n",
       "Name: EstimatedSalary, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salary_column = 'EstimatedSalary'\n",
    "train_data[salary_column].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba6bfd5",
   "metadata": {},
   "source": [
    "We again call `fit()`, imposing a time-limit this time (in seconds), and also demonstrate a shorthand method to evaluate the resulting model on the test data (which contain labels):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36e8f913",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.10.15\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #1 SMP Wed Oct 23 17:17:00 UTC 2024\n",
      "CPU Count:          16\n",
      "Memory Avail:       58.33 GB / 61.79 GB (94.4%)\n",
      "Disk Space Avail:   74.40 GB / 78.56 GB (94.7%)\n",
      "===================================================\n",
      "No presets specified! To achieve strong results with AutoGluon, it is recommended to use the available presets. Defaulting to `'medium'`...\n",
      "\tRecommended Presets (For more details refer to https://auto.gluon.ai/stable/tutorials/tabular/tabular-essentials.html#presets):\n",
      "\tpresets='experimental' : New in v1.2: Pre-trained foundation model + parallel fits. The absolute best accuracy without consideration for inference speed. Does not support GPU.\n",
      "\tpresets='best'         : Maximize accuracy. Recommended for most users. Use in competitions and benchmarks.\n",
      "\tpresets='high'         : Strong accuracy with fast inference speed.\n",
      "\tpresets='good'         : Good accuracy with very fast inference speed.\n",
      "\tpresets='medium'       : Fast training time, ideal for initial prototyping.\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"/home/ec2-user/SageMaker/autogluon-workshops/2024-reinvent/tabular/agModels-predict-salary\"\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 13\n",
      "Label Column:       EstimatedSalary\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (199273.98, 548.52, 112180.30261, 48330.50152)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during Predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression', 'quantile'])\n",
      "Problem Type:       regression\n",
      "Preprocessing data ...\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    59727.15 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 4 | ['Age', 'Balance', 'HasCrCard', 'IsActiveMember']\n",
      "\t\t('int', [])    : 6 | ['id', 'CustomerId', 'CreditScore', 'Tenure', 'NumOfProducts', ...]\n",
      "\t\t('object', []) : 3 | ['Surname', 'Geography', 'Gender']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])  : 2 | ['Surname', 'Geography']\n",
      "\t\t('float', [])     : 2 | ['Age', 'Balance']\n",
      "\t\t('int', [])       : 5 | ['id', 'CustomerId', 'CreditScore', 'Tenure', 'NumOfProducts']\n",
      "\t\t('int', ['bool']) : 4 | ['Gender', 'HasCrCard', 'IsActiveMember', 'Exited']\n",
      "\t0.0s = Fit runtime\n",
      "\t13 features in original data used to generate 13 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.06 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.06s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: KNeighborsUnif ... Training model for up to 59.94s of the 59.94s of remaining time.\n",
      "\t-53380.9993\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.09s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ... Training model for up to 59.84s of the 59.84s of remaining time.\n",
      "\t-54855.8834\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ... Training model for up to 59.76s of the 59.76s of remaining time.\n",
      "\t-49273.4239\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: LightGBM ... Training model for up to 59.39s of the 59.39s of remaining time.\n",
      "\t-49305.9553\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.38s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: RandomForestMSE ... Training model for up to 59.01s of the 59.01s of remaining time.\n",
      "\t-51457.027\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.45s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CatBoost ... Training model for up to 58.50s of the 58.50s of remaining time.\n",
      "\t-48928.1903\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.4s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: ExtraTreesMSE ... Training model for up to 58.09s of the 58.09s of remaining time.\n",
      "\t-51198.8691\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.41s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ... Training model for up to 57.62s of the 57.62s of remaining time.\n",
      "No improvement since epoch 0: early stopping\n",
      "\t-49334.8815\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.62s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: XGBoost ... Training model for up to 56.99s of the 56.99s of remaining time.\n",
      "\t-49142.7244\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ... Training model for up to 56.69s of the 56.69s of remaining time.\n",
      "\t-49355.0769\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.14s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ... Training model for up to 55.54s of the 55.54s of remaining time.\n",
      "\t-49131.1742\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.72s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.94s of the 54.81s of remaining time.\n",
      "\tEnsemble Weights: {'CatBoost': 0.923, 'XGBoost': 0.077}\n",
      "\t-48926.6703\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 5.28s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 27441.6 rows/s (200 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"/home/ec2-user/SageMaker/autogluon-workshops/2024-reinvent/tabular/agModels-predict-salary\")\n"
     ]
    }
   ],
   "source": [
    "predictor_salary = TabularPredictor(label=salary_column, path=\"agModels-predict-salary\").fit(train_data, time_limit=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4564a06d1766c76",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': -50344.53877121951,\n",
       " 'mean_squared_error': -2534572584.0868244,\n",
       " 'mean_absolute_error': -42728.012336640626,\n",
       " 'r2': -0.0063539398953478265,\n",
       " 'pearsonr': 0.0082774732713095,\n",
       " 'median_absolute_error': -40101.941875000004}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_salary.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46af4e18",
   "metadata": {},
   "source": [
    "Note that we didn't need to tell AutoGluon this is a regression problem, it automatically inferred this from the data and reported the appropriate performance metric (root-mean-squared-error (RMSE) by default). To specify a particular evaluation metric other than the default, set the `eval_metric` parameter of [TabularPredictor()](https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.html) and AutoGluon will tailor its models to optimize your metric (e.g. `eval_metric = 'mean_absolute_error'`). For evaluation metrics where higher values are worse (like RMSE), AutoGluon will flip their sign and print them as negative values during training (as it internally assumes higher values are better). You can even specify a custom metric by following the [Custom Metric Tutorial](https://auto.gluon.ai/stable/tutorials/tabular/advanced/tabular-custom-metric.html).\n",
    "\n",
    "We can call leaderboard to see the per-model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6a20746a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>eval_metric</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>-50191.544185</td>\n",
       "      <td>-49305.955285</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.376030</td>\n",
       "      <td>0.002219</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.376030</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>-50212.123525</td>\n",
       "      <td>-49273.423889</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.361889</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.361889</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>-50218.152211</td>\n",
       "      <td>-49131.174213</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.719947</td>\n",
       "      <td>0.002746</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.719947</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>-50265.412638</td>\n",
       "      <td>-49334.881521</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.087555</td>\n",
       "      <td>0.007036</td>\n",
       "      <td>0.615979</td>\n",
       "      <td>0.087555</td>\n",
       "      <td>0.007036</td>\n",
       "      <td>0.615979</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>-50327.849633</td>\n",
       "      <td>-49142.724415</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.014318</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.282491</td>\n",
       "      <td>0.014318</td>\n",
       "      <td>0.004384</td>\n",
       "      <td>0.282491</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>-50344.538771</td>\n",
       "      <td>-48926.670289</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.020038</td>\n",
       "      <td>0.007288</td>\n",
       "      <td>0.691897</td>\n",
       "      <td>0.001226</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.012407</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>-50363.708161</td>\n",
       "      <td>-48928.190329</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.396999</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.002424</td>\n",
       "      <td>0.396999</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetTorch</td>\n",
       "      <td>-50383.239094</td>\n",
       "      <td>-49355.076851</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.021342</td>\n",
       "      <td>0.005959</td>\n",
       "      <td>1.138548</td>\n",
       "      <td>0.021342</td>\n",
       "      <td>0.005959</td>\n",
       "      <td>1.138548</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ExtraTreesMSE</td>\n",
       "      <td>-51110.974921</td>\n",
       "      <td>-51198.869052</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.077434</td>\n",
       "      <td>0.035965</td>\n",
       "      <td>0.413350</td>\n",
       "      <td>0.077434</td>\n",
       "      <td>0.035965</td>\n",
       "      <td>0.413350</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestMSE</td>\n",
       "      <td>-51425.239334</td>\n",
       "      <td>-51457.026995</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.086206</td>\n",
       "      <td>0.036698</td>\n",
       "      <td>0.445432</td>\n",
       "      <td>0.086206</td>\n",
       "      <td>0.036698</td>\n",
       "      <td>0.445432</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>-55190.806865</td>\n",
       "      <td>-53380.999304</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.035202</td>\n",
       "      <td>0.014639</td>\n",
       "      <td>0.085099</td>\n",
       "      <td>0.035202</td>\n",
       "      <td>0.014639</td>\n",
       "      <td>0.085099</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>-56174.886881</td>\n",
       "      <td>-54855.883392</td>\n",
       "      <td>root_mean_squared_error</td>\n",
       "      <td>0.032506</td>\n",
       "      <td>0.014537</td>\n",
       "      <td>0.065556</td>\n",
       "      <td>0.032506</td>\n",
       "      <td>0.014537</td>\n",
       "      <td>0.065556</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model    score_test     score_val              eval_metric  \\\n",
       "0              LightGBM -50191.544185 -49305.955285  root_mean_squared_error   \n",
       "1            LightGBMXT -50212.123525 -49273.423889  root_mean_squared_error   \n",
       "2         LightGBMLarge -50218.152211 -49131.174213  root_mean_squared_error   \n",
       "3       NeuralNetFastAI -50265.412638 -49334.881521  root_mean_squared_error   \n",
       "4               XGBoost -50327.849633 -49142.724415  root_mean_squared_error   \n",
       "5   WeightedEnsemble_L2 -50344.538771 -48926.670289  root_mean_squared_error   \n",
       "6              CatBoost -50363.708161 -48928.190329  root_mean_squared_error   \n",
       "7        NeuralNetTorch -50383.239094 -49355.076851  root_mean_squared_error   \n",
       "8         ExtraTreesMSE -51110.974921 -51198.869052  root_mean_squared_error   \n",
       "9       RandomForestMSE -51425.239334 -51457.026995  root_mean_squared_error   \n",
       "10       KNeighborsUnif -55190.806865 -53380.999304  root_mean_squared_error   \n",
       "11       KNeighborsDist -56174.886881 -54855.883392  root_mean_squared_error   \n",
       "\n",
       "    pred_time_test  pred_time_val  fit_time  pred_time_test_marginal  \\\n",
       "0         0.002219       0.002328  0.376030                 0.002219   \n",
       "1         0.002706       0.002227  0.361889                 0.002706   \n",
       "2         0.002746       0.002441  0.719947                 0.002746   \n",
       "3         0.087555       0.007036  0.615979                 0.087555   \n",
       "4         0.014318       0.004384  0.282491                 0.014318   \n",
       "5         0.020038       0.007288  0.691897                 0.001226   \n",
       "6         0.004494       0.002424  0.396999                 0.004494   \n",
       "7         0.021342       0.005959  1.138548                 0.021342   \n",
       "8         0.077434       0.035965  0.413350                 0.077434   \n",
       "9         0.086206       0.036698  0.445432                 0.086206   \n",
       "10        0.035202       0.014639  0.085099                 0.035202   \n",
       "11        0.032506       0.014537  0.065556                 0.032506   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.002328           0.376030            1       True   \n",
       "1                 0.002227           0.361889            1       True   \n",
       "2                 0.002441           0.719947            1       True   \n",
       "3                 0.007036           0.615979            1       True   \n",
       "4                 0.004384           0.282491            1       True   \n",
       "5                 0.000480           0.012407            2       True   \n",
       "6                 0.002424           0.396999            1       True   \n",
       "7                 0.005959           1.138548            1       True   \n",
       "8                 0.035965           0.413350            1       True   \n",
       "9                 0.036698           0.445432            1       True   \n",
       "10                0.014639           0.085099            1       True   \n",
       "11                0.014537           0.065556            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0           4  \n",
       "1           3  \n",
       "2          11  \n",
       "3           8  \n",
       "4           9  \n",
       "5          12  \n",
       "6           6  \n",
       "7          10  \n",
       "8           7  \n",
       "9           5  \n",
       "10          1  \n",
       "11          2  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor_salary.leaderboard(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d692ceb",
   "metadata": {},
   "source": [
    "**Data Formats:** AutoGluon can currently operate on data tables already loaded into Python as pandas DataFrames, or those stored in files of [CSV format](https://en.wikipedia.org/wiki/Comma-separated_values) or [Parquet format](https://databricks.com/glossary/what-is-parquet). If your data lives in multiple tables, you will first need to join them into a single table whose rows correspond to statistically independent observations (datapoints) and columns correspond to different features (aka. variables/covariates).\n",
    "\n",
    "Refer to the [TabularPredictor documentation](https://auto.gluon.ai/stable/api/autogluon.tabular.TabularPredictor.html) to see all of the available methods/options."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e97d259",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Please continue to the next workshop section on **\"Tabular regression & classification/In-depth functionality\"**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
