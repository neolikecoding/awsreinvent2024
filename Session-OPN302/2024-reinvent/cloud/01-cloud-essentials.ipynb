{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Deploy AutoGluon Models on SageMaker with AutoGluon Cloud\n",
    "\n",
    "To help with AutoGluon models training, AWS developed a set of training and inference [deep learning containers](https://github.com/aws/deep-learning-containers/blob/master/available_images.md#autogluon-training-containers). \n",
    "The containers can be used to train models with CPU and GPU instances and deployed as a SageMaker endpoint or used as a batch transform job.\n",
    "\n",
    "We offer the [autogluon.cloud](https://github.com/autogluon/autogluon-cloud) module to utilize those containers and [AWS SageMaker](https://aws.amazon.com/sagemaker/) underneath to train/deploy AutoGluon backed models with simple APIs.\n",
    "\n",
    "```{attention}\n",
    "Costs for running cloud compute are managed by AWS SageMaker, and storage costs are managed by AWS S3. AutoGluon-Cloud is a wrapper to these services at no additional charge. While AutoGluon-Cloud makes an effort to simplify the usage of these services, it is ultimately the user's responsibility to monitor compute usage within their account to avoid unexpected charges.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Installation\n",
    "`autogluon.cloud` does not come with the default `autogluon` installation. You can install it via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q uv\n",
    "!uv pip install -q autogluon.cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also ensure that the latest version of sagemaker python API is installed via:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -U sagemaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is required to ensure the information about newly released containers is available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Configuration\n",
    "Replace `S3_BUCKET_PATH` with the name of the S3 bucket created by CloudFormation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_BUCKET_PATH = \"s3://YOUR_S3_BUCKET_PATH\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Using `autogluon.cloud` to train AutoGluon backed models is simple and not too much different from training an AutoGluon predictor directly.\n",
    "\n",
    "Currently, `autogluon.cloud` supports training/deploying `tabular`, `multimodal`, `text`, and `image` predictors. In the example below, we use `TabularCloudPredictor` for demonstration. You can substitute it with other `CloudPredictors` easily as they share the same APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.cloud import TabularCloudPredictor\n",
    "\n",
    "train_data = \"https://autogluon.s3.amazonaws.com/datasets/Inc/train.csv\"  # can be a DataFrame as well\n",
    "predictor_init_args = {\"label\": \"class\"}  # init args you would pass to AG TabularPredictor\n",
    "predictor_fit_args = {\"train_data\": train_data, \"time_limit\": 120}  # fit args you would pass to AG TabularPredictor\n",
    "\n",
    "cloud_predictor = TabularCloudPredictor(\n",
    "    cloud_output_path=S3_BUCKET_PATH\n",
    ").fit(\n",
    "    predictor_init_args=predictor_init_args,\n",
    "    predictor_fit_args=predictor_fit_args,\n",
    "    instance_type=\"ml.m5.2xlarge\",  # Checkout supported instance and pricing here: https://aws.amazon.com/sagemaker/pricing/\n",
    "    wait=True,  # Set this to False to make it an unblocking call and immediately return\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reattach to a Previous Training Job\n",
    "If your local connection to the training job died for some reason, i.e. lost internet connection, your training job will still be running on SageMaker, and you can reattach to the job with another `CloudPredictor` as long as you have the job name.\n",
    "\n",
    "The job name will be logged out when the training job started.\n",
    "It should look similar to this: `INFO:sagemaker:Creating training-job with name: ag-cloudpredictor-1673296750-47d7`.\n",
    "Alternatively, you can go to the SageMaker console and find the ongoing training job and its corresponding job name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the following lines to reattach to a previous training job if the training job died\n",
    "## Substitute `JOB_NAME` with the actual job name from the log\n",
    "\n",
    "\n",
    "# another_cloud_predictor = TabularCloudPredictor()\n",
    "# another_cloud_predictor.attach_job(job_name=\"JOB_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reattached job will no longer give live stream of the training job's log. Instead, the log will be available once the training job is finished."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Endpoint Deployment and Real-time Prediction\n",
    "If you want to deploy a predictor as a SageMaker endpoint, which can be used to do real-time inference later, it is just one line of code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_predictor.deploy(\n",
    "    instance_type=\"ml.m5.2xlarge\",  # Checkout supported instance and pricing here: https://aws.amazon.com/sagemaker/pricing/\n",
    "    wait=True,  # Set this to False to make it an unblocking call and immediately return\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally, you can also attach to a deployed endpoint:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the following lines to attach to a deployed endpoint if the endpoint died\n",
    "## Substitute `ENDPOINT_NAME` with the actual endpoint name from the log\n",
    "\n",
    "# cloud_predictor.attach_endpoint(endpoint=\"ENDPOINT_NAME\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform real-time prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cloud_predictor.predict_real_time(\"https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv\") # can be a DataFrame as well\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result would be a pandas Series similar to this:\n",
    "\n",
    "```python\n",
    "0     <=50K\n",
    "1     <=50K\n",
    "2      >50K\n",
    "3     <=50K\n",
    "4     <=50K\n",
    "Name: class, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform real-time predict probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cloud_predictor.predict_proba_real_time(\"https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv\")  # can be a DataFrame as well\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result would be a pandas DataFrame similar to this:\n",
    "\n",
    "```python\n",
    "\t<=50K\t    >50K\n",
    "0\t0.931060\t0.068940\n",
    "1\t0.997505\t0.002495\n",
    "2\t0.028420\t0.971580\n",
    "3\t0.997988\t0.002012\n",
    "4\t0.999332\t0.000668\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To identify if you have an active endpoint attached:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_predictor.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code above would return you a dict showing general info of the CloudPredictor.\n",
    "One key inside would be `endpoint`, and it will tell you the name of the endpoint if there's an attached one, i.e."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "{\n",
    "    ...\n",
    "    'endpoint': 'ag-cloudpredictor-1668189208-d23b'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invoke the Endpoint without AutoGluon Cloud\n",
    "The endpoint being deployed is a normal Sagemaker Endpoint, and you can invoke it through other methods. For example, to invoke an endpoint with boto3 directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "ENDPOINT_NAME = cloud_predictor.info()['endpoint']\n",
    "\n",
    "client = boto3.client('sagemaker-runtime')\n",
    "test_data = pd.read_csv(\"https://autogluon.s3.amazonaws.com/datasets/Inc/test.csv\").drop(columns=['class'])\n",
    "response = client.invoke_endpoint(\n",
    "    EndpointName=ENDPOINT_NAME,\n",
    "    ContentType='text/csv',\n",
    "    Accept='application/json',\n",
    "    Body=test_data.to_csv(index=False)\n",
    ")\n",
    "\n",
    "predictions = json.loads(response['Body'].read().decode())\n",
    "print(json.dumps(predictions[:3], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you clean up the endpoint deployed by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_predictor.cleanup_deployment()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Inference\n",
    "When minimizing latency isn't a concern, then the batch inference functionality may be easier, more scalable, and cheaper as compute is automatically terminated after the batch inference job is complete.\n",
    "\n",
    "A general guideline is to use batch inference if you need to get predictions less than once an hour and are ok with the inference time taking 10 minutes longer than real-time inference (due to compute spin-up overhead).\n",
    "\n",
    "To perform batch inference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cloud_predictor.predict(\n",
    "    test_data=test_data,  # can be a DataFrame as well and the results will be stored in s3 bucket\n",
    "    instance_type=\"ml.m5.2xlarge\",  # Checkout supported instance and pricing here: https://aws.amazon.com/sagemaker/pricing/\n",
    "    wait=True,  # Set this to False to make it an unblocking call and immediately return\n",
    ")\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result would be a pandas DataFrame similar to this:\n",
    "\n",
    "```python\n",
    "0     <=50K\n",
    "1     <=50K\n",
    "2      >50K\n",
    "3     <=50K\n",
    "4     <=50K\n",
    "Name: class, dtype: object\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform batch inference and getting prediction probability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment the following cells to also output the prediction probabilities\n",
    "\n",
    "# predictions, predictions_proba = cloud_predictor.predict_proba(\n",
    "#     test_data=test_data,  # can be a DataFrame as well and the results will be stored in s3 bucket\n",
    "#     include_predict=True,  # Will return a tuple (prediction, prediction probability). Set this to False to get prediction probability only.\n",
    "#     instance_type=\"ml.m5.2xlarge\",  # Checkout supported instance and pricing here: https://aws.amazon.com/sagemaker/pricing/\n",
    "#     wait=True,  # Set this to False to make it an unblocking call and immediately return\n",
    "# )\n",
    "# print(predictions.head())\n",
    "# print(predictions_proba.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result would be a tuple containing both the prediction and prediction probability if `include_predict` is True, i.e.\n",
    "\n",
    "```python\n",
    "0     <=50K\n",
    "1     <=50K\n",
    "2      >50K\n",
    "3     <=50K\n",
    "4     <=50K\n",
    "Name: class, dtype: object\n",
    "```\n",
    "\n",
    "Otherwise, prediction probability only, i.e.\n",
    "\n",
    "```python\n",
    "   <=50K     >50K\n",
    "0  0.931060  0.068940\n",
    "1  0.997505  0.002495\n",
    "2  0.028420  0.971580\n",
    "3  0.997988  0.002012\n",
    "4  0.999332  0.000668\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve CloudPredictor Info\n",
    "\n",
    "To retrieve general info about a `CloudPredictor`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_predictor.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will output a dict similar to this:\n",
    "\n",
    "```\n",
    "{\n",
    "    'local_output_path': '/home/ubuntu/XXX/demo/AutogluonCloudPredictor/ag-20221111_174928',\n",
    "    'cloud_output_path': 's3://XXX/tabular-demo',\n",
    "    'fit_job': {\n",
    "        'name': 'ag-cloudpredictor-1668188968-e5c3',\n",
    "        'status': 'Completed',\n",
    "        'framework_version': '0.6.1',\n",
    "        'artifact_path': 's3://XXX/tabular-demo/model/ag-cloudpredictor-1668188968-e5c3/output/model.tar.gz'\n",
    "    },\n",
    "    'recent_transform_job': {\n",
    "        'name': 'ag-cloudpredictor-1668189393-e95c',\n",
    "        'status': 'Completed',\n",
    "        'result_path': 's3://XXX/tabular-demo/batch_transform/2022-11-11-17-56-33-991/results/test.csv.out'\n",
    "    },\n",
    "    'transform_jobs': ['ag-cloudpredictor-1668189393-e95c'],\n",
    "    'endpoint': 'ag-cloudpredictor-1668189208-d23b'\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
